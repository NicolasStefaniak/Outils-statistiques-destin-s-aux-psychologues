<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Les différentes méthodes d’inférences statistiques | Outils statistiques destinés aux psychologues</title>
<meta name="author" content="Nicolas Stefaniak">
<meta name="description" content="“Le statisticien ne peut pas se soustraire à l’obligation d’être au clair quant aux principes de l’inférence scientifique, mais de même, aucune autre personne censée ne peut se soustraire à une...">
<meta name="generator" content="bookdown 0.44 with bs4_book()">
<meta property="og:title" content="Chapter 9 Les différentes méthodes d’inférences statistiques | Outils statistiques destinés aux psychologues">
<meta property="og:type" content="book">
<meta property="og:description" content="“Le statisticien ne peut pas se soustraire à l’obligation d’être au clair quant aux principes de l’inférence scientifique, mais de même, aucune autre personne censée ne peut se soustraire à une...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 9 Les différentes méthodes d’inférences statistiques | Outils statistiques destinés aux psychologues">
<meta name="twitter:description" content="“Le statisticien ne peut pas se soustraire à l’obligation d’être au clair quant aux principes de l’inférence scientifique, mais de même, aucune autre personne censée ne peut se soustraire à une...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/panelset-0.3.0/panelset.css" rel="stylesheet">
<script src="libs/panelset-0.3.0/panelset.js"></script><link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="libs/tabwid-1.1.3/tabwid.js"></script><link href="libs/htmltools-fill-0.5.9/fill.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.34.0/datatables.js"></script><link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script><link href="libs/crosstalk-1.2.2/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.2/js/crosstalk.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Outils statistiques destinés aux psychologues</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"></a></li>
<li><a class="" href="licence.html">Licence</a></li>
<li><a class="" href="pourquoi-les-statistiques.html"><span class="header-section-number">1</span> Pourquoi les statistiques</a></li>
<li><a class="" href="quel-logiciel-utiliser-et-pourquoi.html"><span class="header-section-number">2</span> Quel logiciel utiliser et pourquoi ?</a></li>
<li><a class="" href="installer-le-logiciel-de-traitement-de-donn%C3%A9es.html"><span class="header-section-number">3</span> Installer le logiciel de traitement de données</a></li>
<li><a class="" href="d%C3%A9buter-avec-son-logiciel-de-statistiques.html"><span class="header-section-number">4</span> Débuter avec son logiciel de statistiques</a></li>
<li><a class="" href="les-donn%C3%A9es.html"><span class="header-section-number">5</span> Les données</a></li>
<li><a class="" href="organiser-les-donn%C3%A9es.html"><span class="header-section-number">6</span> Organiser les données</a></li>
<li><a class="" href="pr%C3%A9parer-les-donn%C3%A9es.html"><span class="header-section-number">7</span> Préparer les données</a></li>
<li><a class="" href="les-statistiques-descriptives.html"><span class="header-section-number">8</span> Les statistiques descriptives</a></li>
<li><a class="active" href="les-diff%C3%A9rentes-m%C3%A9thodes-dinf%C3%A9rences-statistiques.html"><span class="header-section-number">9</span> Les différentes méthodes d’inférences statistiques</a></li>
<li><a class="" href="quel-outil-choisir.html"><span class="header-section-number">10</span> Quel outil choisir</a></li>
<li><a class="" href="r%C3%A9f%C3%A9rences.html"><span class="header-section-number">11</span> Références</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="les-différentes-méthodes-dinférences-statistiques" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Les différentes méthodes d’inférences statistiques<a class="anchor" aria-label="anchor" href="#les-diff%C3%A9rentes-m%C3%A9thodes-dinf%C3%A9rences-statistiques"><i class="fas fa-link"></i></a>
</h1>
<blockquote>
<p>“Le statisticien ne peut pas se soustraire à l’obligation d’être au clair quant aux principes de l’inférence scientifique, mais de même, aucune autre personne censée ne peut se soustraire à une telle obligation.”</p>
<footer>
— Sir Ronald Fisher
</footer>
</blockquote>
<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
</style>
<div style="background:      #f0e1ff   ; font-size: 20px; padding: 10px; border: 1px solid lightlilac; margin: 10px;">
<p><legend style="background:  #ead2ff   ;font-size: 30px; padding: 10px; border: 1px solid lilac;margin: 0 px">
<strong>Résumé</strong> </legend></p>
<p style="text-align:justify;">
</p>
<p>Dans ce chapitre nous aborderons les trois principales écoles de pensées pour l’inférence statistique :</p>
<ul>
<li>l’approche de Neyman-Pearson</li>
<li>l’approche de vraisemblance</li>
<li>l’approche bayésienne</li>
</ul>
<p>Nous aborderons les tenants et les aboutissants de ces différents méthodes, leurs avantages et leurs inconvénients.
L’objectif est de permettre au lecteur d’avoir les notions indispensables pour lire, comprendre ou réaliser des analsyes statistiques selon n’importe laquelle des écoles d’inférence, et de pouvoir développer un regard critique sur chacune de ces écoles.</p>

</div>
<div style="background:      #EFEDE9   ; font-size: 20px; padding: 10px; border: 1px solid lightlilac; margin: 10px;">
<p><legend style="background:  #DED9D1   ;font-size: 30px; padding: 10px; border: 1px solid lilac;margin: 0 px">
<strong>Prérequis</strong> </legend></p>
<p style="text-align:justify;">
</p>
<p><strong>D’un point de vue théorique</strong></p>
<ul>
<li>Savoir ce qu’est une distribution normale.</li>
<li>Savoir ce qu’est une moyenne, un écart-type et une erreur-type</li>
<li>Savoir ce qu’est le score z</li>
</ul>
</div>
<div id="introduction-2" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-2"><i class="fas fa-link"></i></a>
</h2>
<p>Les statistiques permettent de tester des hypothèses, ces hypothèses peuvent être de nature extrêmement différentes :</p>
<ul>
<li><p>De combien de béton ai-je besoin pour éviter qu’un pont d’autoroute ne s’écroule avec un risque d’erreur de 1/100 000 ?</p></li>
<li><p>Est-ce que ce traitement est efficace ?</p></li>
<li><p>Est-ce que les oiseaux migratoires prennent toujours la même route ?</p></li>
<li><p>Est-ce que des enfants apprennent mieux avec la méthode A ou avec la méthode B ?</p></li>
<li><p>Quelle date de péremption faut-il mettre sur les emballages pour s’assurer que le produit ne sera pas périmé dans 99.9% des situations ?</p></li>
<li><p>Quelle est la méthode la plus efficace pour faire comprendre les statistiques aux étudiants ?</p></li>
</ul>
<p>Toutes ces questions amènent des hypothèses. Par exemple, mes calculs permettent de prédire qu’il faut X tonnes de béton pour s’assurer que le pont ne fissure pas dans plus d’un 1 car sur 100 000.</p>
<p>On peut raisonnablement se demander comment il est possible de répondre de manière fiable à ces questions. Il existe au minimum trois approches différentes pour apporter des éléments de réponses : l’approche de Neyman-Pearson <span class="citation">(<a href="r%C3%A9f%C3%A9rences.html#ref-Neyman1933">1933</a>)</span>, l’approche bayésienne <span class="citation">(<a href="r%C3%A9f%C3%A9rences.html#ref-Bayes1763">Bayes &amp; Price, 1763</a>; <a href="r%C3%A9f%C3%A9rences.html#ref-LaPlace1814">LaPlace, 1814</a>)</span> et l’approche par vraisemblance <span class="citation">(<a href="r%C3%A9f%C3%A9rences.html#ref-royall1997statistical">Royall, 1997</a>)</span>.</p>
<p>Dans ce chapitre, nous allons considérer que l’approche de Neyman-Pearson <span class="citation">(<a href="r%C3%A9f%C3%A9rences.html#ref-Neyman1933">1933</a>)</span> est la plus indispensable pour débuter avec l’inférence statistique car c’est l’approche la plus communément rencontrée dans la littérature scientifique. Il est donc nécessaire de pouvoir apporter les bases théoriques nécessaires à la lecture des statistiques selon cette approche. Ainsi, dans ce chapitre, vous pourrez être dans une logique de <em>découverte de l’inférence statistique</em> et vous limitez à lire et comprendre l’approche de Neyman-Pearson <span class="citation">(<a href="r%C3%A9f%C3%A9rences.html#ref-Neyman1933">1933</a>)</span>, être déjà au fait avec cette approche et découvrir une autre école d’inférence statistique ou enfin vouloir découvrir naïvement les différentes écoles de pensées et vous faire votre propre opinion sur celle qui vous correspond le mieux. Dans le premier et second cas de figure, vous pourrez concentrer votre lecture sur l’école de pensées qui vous intéresse et dans le dernier cas de figure, vous ne pourrez pas faire l’économie d’une lecture complète de ce chapitre.</p>
<p>Si, pour toutes les approches, nous essaierons d’aborder les choses de manière assez intuitive dans un premier temps, ce chapitre est tellement important que ce serait une erreur d’aborder les choses que de manière superficielle. Ainsi, après cette première phase plus intuitive, nous aborderons progressivement les choses de manière plus technique. S’assurer d’une bonne compréhension de la méthode d’inférence que vous voudrez utiliser ou analyser est non seulement indispensable pour utiliser de manière adaptée les outils mais facilitera la compréhension des autres chapitres.</p>
</div>
<div id="lapproche-de-neyman-pearson" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> L’approche de Neyman-Pearson<a class="anchor" aria-label="anchor" href="#lapproche-de-neyman-pearson"><i class="fas fa-link"></i></a>
</h2>
<div id="une-approche-intuitive" class="section level3" number="9.2.1">
<h3>
<span class="header-section-number">9.2.1</span> Une approche intuitive<a class="anchor" aria-label="anchor" href="#une-approche-intuitive"><i class="fas fa-link"></i></a>
</h3>
<p>Imaginons qu’un chercheur développe un médicament qui rend les gens intelligents. Pour montrer l’efficacité de son traitement, il faut passer un test d’intelligence à un groupe de personnes, il donne son traitement miraculeux à ce groupe et au bout de quelques semaines de traitement, il évalue à nouveau le niveau intellectuel de ces personnes (avec un autre test pour éviter les effets d’apprentissage mais qui est tout aussi bien standardisé). Il observe que la moyenne au temps 1 est de 100 et que la moyenne au temps 2 est 100,1. Après son expérimentation, ce chercheur présente les résultats de son étude en affirmant haut et fort que son traitement rend plus intelligent. Probablement, que face à cette affirmation, vous pourriez être amusé·e, mais probablement pas convaincu·e. La question qui se pose est de savoir à partir de quel moment vous seriez convaincu·e. la réponse à cette question est simple : à partir du moment où la différence observée fait sens. D’un point de vue statistique, c’est ce qu’on appelle la significativité<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;nous verrons plus loin les limites de la significativité telle que nous allons la décrire dans cette partie&lt;/p&gt;"><sup>10</sup></a>.</p>
<p>Pour comprendre intuitivement la notion de significativité, demandez-vous si l’intelligence d’Albert Einstein est une intelligence exceptionnelle, ou une intelligence typique de la population humaine.</p>
<div class="inline-figure"><img src="inference/Einstein.png" width="300px"></div>
<p>Si vous aboutissez à la conclusion qu’Albert Einstein a une intelligence exceptionnelle, cela signifie que vous considérez que son intelligence est significativement différente de celle de la population générale.</p>
<p>La raison pour laquelle vous arrivez à la conclusion qu’Einstein est quelqu’un de particulièrement intelligent est que, de manière générale, on voit peu de personnes ayant réalisé autant d’accomplissement scientifiques et que, pour atteindre un tel niveau d’accomplissement, il est nécessaire que cette personne ait une intelligence très développée. L’idée sous-tendant les tests statistiques est d’estimer la probabilité de croiser une personnes aussi intelligente ou plus intelligente qu’Albert Einstein en considérant que ce niveau intellectuel ne se distingue pas de celui de la population générale.</p>
<p>Ainsi, en considérant dans un premier temps qu’Albert Einstein a une intelligence qu’on peut observer de manière générale dans la population, on considère qu’Albert Einstein ne se différencie pas de la population générale. D’un point de vue statistique, cette absence de différence est ce qu’on appelle une hypothèse nulle, souvent dénoté <span class="math inline">\(H_0\)</span>.</p>
<p>Pour tester cette hypothèse, on peut utiliser un tester évaluant le quotient intellectuel (QI).
La moyenne pour une échelle de QI est de 100 et l’écart-type est de 15. On considère que le niveau d’intelligence se distribue en suivant une distribution normale. Sachant qu’Einstein avait un QI estimé à 162, on peut calculer la probabilité d’obtenir un QI aussi élevé ou plus élevé que le sien. Nous pouvons obtenir cette probabilité à l’aide du score z, qui est obtenu par la formule <a href="les-diff%C3%A9rentes-m%C3%A9thodes-dinf%C3%A9rences-statistiques.html#eq:scorez">(9.1)</a> :</p>
<p><span class="math display" id="eq:scorez">\[\begin{equation}
z=\frac{x_i-\bar{x}}{s}
\tag{9.1}
\end{equation}\]</span></p>
<p>Dans R, c’est la fonction <code>pnorm</code> qui permet de réaliser le score Z. Cette fonction a 4 arguments :</p>
<ul>
<li><p><code>q</code> : le score <span class="math inline">\(x_i\)</span> de l’individu</p></li>
<li><p><code>mean</code> : la moyenne du groupe de référence</p></li>
<li><p><code>sd</code> : l’écart-type du groupe de référence</p></li>
<li><p><code>lower.tail</code> : permet de choisir le côté de la courbe (<code>lower.tail = TRUE</code> signifie qu’on calcule la probabilité pour les scores inférieurs ou égal au <span class="math inline">\(x_i\)</span> et <code>lower.tail = FALSE</code> pour les scrores supérieurs ou égal au <span class="math inline">\(x_i\)</span>)</p></li>
</ul>
<div class="sourceCode" id="cb288"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span>q<span class="op">=</span><span class="fl">162</span>, mean <span class="op">=</span> <span class="fl">100</span>, sd <span class="op">=</span> <span class="fl">15</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 1.787698e-05</code></pre>
<p>Avec une probabilité de <span class="math inline">\(1.78 \times 10^{-5}\)</span>, on trouve moins de deux personnes sur 100 000 ayant une intelligence aussi élevée ou plus élevée que celle d’Albert Einstein. Ainsi, la probabilité de croiser quelqu’un d’aussi intelligent qu’Albert Einstein est très faible, c’est pour cela que nous avons considéré intuitivement qu’il avait un QI qui se distinguait significativement de la plupart des gens.
Il faut donc comprendre qu’on considère qu’il y a une différence significative lorsque la probabilité d’observer un phénomène au regard de la distribution sur laquelle on s’appuie est faible.</p>
<p>Pour le formuler autrement, la probabilité associée à un test statistique dans le cadre des tests d’hypothèse nulle est la probabilité d’observer une telle différence (avoir un QI de 162 signifie qu’il y a une différence de 62 points par rapport à la moyenne) si cette différence est vraie (le QI d’Einstein aurait pu être un QI égal à 100).</p>
<p>Ainsi, si la probabilité d’observer cette différence est faible, alors, on va considérer cette différence comme étant significative car il y a peu de chance que cette différence soit observé uniquement en raison du fruit du hasard.
Habituellement, on considère que la probabilité est faible si la probabilité associée au test statistique est inférieure à 0.05. C’est ce qu’on appelle le seuil de significativité.</p>
<p>Ainsi, dans le Figure <a href="les-diff%C3%A9rentes-m%C3%A9thodes-dinf%C3%A9rences-statistiques.html#fig:unilat">9.1</a>, la barre verticale représente le seuil de significativité à 5% lorsqu’on considère que seul un côté de la courbe est digne d’intérêt. On parle dans ce cas d’hypothèse unilatérale.
En d’autres termes, dans une hypothèse unilatérale, on considère que seul les 5% supérieurs de notre distribution sont intéressants pour tester notre hypothèse. Le seuil de significativité sera placé sur l’extrémité d’intérêt de la distribution. Pour reprendre l’exemple sur le QI. Au-delà d’Albert Einstein, on va considérer que quelqu’un a un niveau intellectuel qui se distingue significativement si son QI est supérieur à 124.6728, indiqué par la barre verticale l’indique dans la Figure <a href="les-diff%C3%A9rentes-m%C3%A9thodes-dinf%C3%A9rences-statistiques.html#fig:unilat">9.1</a>.</p>
<div class="sourceCode" id="cb290"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fl">100</span>,<span class="fl">15</span><span class="op">)</span></span>
<span> <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">40</span>,<span class="fl">160</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">x</span>,freq<span class="op">=</span><span class="cn">FALSE</span>,col<span class="op">=</span><span class="fl">0</span>,ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0.05</span><span class="op">)</span>,<span class="fl">20</span>, xlab<span class="op">=</span><span class="cn">NULL</span>, ylab<span class="op">=</span><span class="st">"Densité"</span>, main<span class="op">=</span><span class="cn">NULL</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">100</span>,<span class="fl">15</span><span class="op">)</span>,xlim<span class="op">=</span><span class="va">r</span>,col<span class="op">=</span><span class="fl">3</span>,add<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span> <span class="va">cutoff</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="fl">100</span>, <span class="fl">15</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v<span class="op">=</span><span class="va">cutoff</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>y<span class="op">=</span><span class="fl">0.005</span>, x<span class="op">=</span><span class="fl">135</span> ,labels <span class="op">=</span><span class="st">"5%"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:unilat"></span>
<img src="bookdown-demo_files/figure-html/unilat-1.png" alt="Seuil de significativité pour une hypothèse unilatérale" width="672"><p class="caption">
Figure 9.1: Seuil de significativité pour une hypothèse unilatérale
</p>
</div>
<div class="sourceCode" id="cb291"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">cutoff</span></span></code></pre></div>
<pre><code>## [1] 124.6728</code></pre>
<p>Une autre manière de répartir les 5% est d’estimer que le QI d’une personne se distingue significativement dès lors qu’elle appartient au 5% d’une des deux extrémités de la courbe.
Dans ce cas, il faut répartir les 5% sur les deux extrémités, ce qui signifie que le seuil de significativité est atteint lorsqu’une personne a un QI inférieur ou égal aux 2.5% à l’extrémité gauche de la courbe (i.e., les QI les plus faibles) ou aux 2.5% à l’extrémité droite de la courbe (i.e., les QI les plus élevés), voir Figure <a href="#fig:bilat"><strong>??</strong></a>.</p>
<div class="sourceCode" id="cb293"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">cutoff1</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">100</span>, <span class="fl">15</span><span class="op">)</span></span>
<span> <span class="va">cutoff2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">100</span>, <span class="fl">15</span><span class="op">)</span></span>
<span> <span class="va">cutoff1</span></span></code></pre></div>
<pre><code>## [1] 70.60054</code></pre>
<div class="sourceCode" id="cb295"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">cutoff2</span></span></code></pre></div>
<pre><code>## [1] 129.3995</code></pre>
<div class="sourceCode" id="cb297"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100000</span>, <span class="fl">100</span>,<span class="fl">15</span><span class="op">)</span></span>
<span> <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">40</span>,<span class="fl">160</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">x</span>,freq<span class="op">=</span><span class="cn">FALSE</span>,col<span class="op">=</span><span class="fl">0</span>,ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0.05</span><span class="op">)</span>,<span class="fl">20</span>, xlab<span class="op">=</span><span class="cn">NULL</span>, ylab<span class="op">=</span><span class="st">"Densité"</span>, main<span class="op">=</span><span class="cn">NULL</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">100</span>,<span class="fl">15</span><span class="op">)</span>,xlim<span class="op">=</span><span class="va">r</span>,col<span class="op">=</span><span class="fl">3</span>,add<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v<span class="op">=</span><span class="va">cutoff1</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v<span class="op">=</span><span class="va">cutoff2</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>y<span class="op">=</span><span class="fl">0.005</span>, x<span class="op">=</span><span class="fl">145</span> ,labels <span class="op">=</span><span class="st">"2.5%"</span><span class="op">)</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>y<span class="op">=</span><span class="fl">0.005</span>, x<span class="op">=</span><span class="fl">50</span> ,labels <span class="op">=</span><span class="st">"2.5%"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:biltat"></span>
<img src="bookdown-demo_files/figure-html/biltat-1.png" alt="Seuil de significativité pour une hypothèse bilatérale" width="672"><p class="caption">
Figure 9.2: Seuil de significativité pour une hypothèse bilatérale
</p>
</div>
<p>Dans le premier cas de figure, on parle d’hypothèse unilatérale et dans le second cas de figure, on parle d’hypothèse bilatérale. Il est raisonnable d’utiliser le premier cas de figure uniquement lorsque les éléments théoriques sur lesquels on s’appuie pour tester l’hypothèse sont extrêmement robustes, et même dans ce cas, cela est, la plupart du temps, considéré comme insuffisant pour justifier une hypothèse unilatérale.</p>
<p>Ainsi, si une personne a un QI de 135, on va rejeter l’hypothèse nulle et considérer qu’il y a une différence significative. Quand on conclut à la présence d’une différence significative, c’est que les données permettent d’étayer une autre hypothèse que l’hypothèse nulle : cette autre hypothèse est l’hypothèse d’une différence. On l’appelle <strong>l’hypothèse alternative</strong>. Tous les tests statistiques sont construits sur le même principe : ils opposent une hypothèse nulle à une hypothèse alternative. De manière systématique, l’hypothèse nulle doit être formalisée sous la forme d’une absence de différence et l’hypothèse alternative en termes de la présence d’une différence. Bien que cela semble simple lorsqu’on présente les choses ainsi, il n’est pas si simple de pouvoir générer ces deux hypothèses si on ne comprend pas à quoi sert le test, ce qui peut entraîner des erreurs d’interprétation. Cependant, si vous entraînez à formuler les hypothèses nulles et alternatives correctement, vous pourrez facilement transposer à de nouvelles situations que vous n’aurez jamais rencontrées en appliquant le même principe.</p>
<p>Dans le cas d’Einstein, il n’était pas nécessaire de tester statistiquement l’hypothèse pour connaître la réponse car on savait qu’il s’agit d’une personne particulièrement intelligente. Le problème est que, dans la réalité, on ne connait pas la réponse à la question que l’on se pose avant d’avoir mis à l’épreuve cette question. Ainsi, si on estime le QI d’une personne, c’est par exemple, pour essayer de comprendre pourquoi cette personne est en échec scolaire. Ainsi, on pourrait faire l’hypothèse que son niveau intellectuel est faible, mais on pourrait également faire l’hypothèse que, en raison de son niveau intellectuel élevé, elle s’ennuie à l’école, elle se désintéresse de ses cours, ce qui la fait échouer.</p>
<p>Dans la section suivante, nous allons décrire comment la significativité est déterminée et ce qu’elle signifie à partir dun exemple de travail plutôt simple.</p>
</div>
<div id="quid-quand-cest-moins-évident" class="section level3" number="9.2.2">
<h3>
<span class="header-section-number">9.2.2</span> Quid quand c’est moins évident?<a class="anchor" aria-label="anchor" href="#quid-quand-cest-moins-%C3%A9vident"><i class="fas fa-link"></i></a>
</h3>
<p>Une jeune femme fait l’hypothèse qu’il est possible de rencontrer l’homme de sa vie en sortant dans un bar. Elle n’est pas tout à fait naïve est sait très bien que la plupart des hommes ne seront pas son prince charmant. Pour accorder une chance au jeune homme qui viendra la trouver, elle va donc opérationnaliser son hypothèse en considérant que l’homme de sa vie sera en mesure de l’intéresser pendant au moins 90 minutes. Elle lui donnera donc son numéro qu’à cette condition.</p>
<p>Pour formaliser les choses, les hommes géniaux doivent intéresser notre jeune femme pendant 5400 secondes. Néanmoins, dans la catégorie des hommes géniaux, il y en a qui sont moins bavards, il y en a qui sont plus timides. Donc, les hommes géniaux vont en réalité se distribuer autour de la moyenne de 5400 secondes avec un écart-type de 1000 seconde en suivant la distribution présentée en Figure 3.</p>
<div class="sourceCode" id="cb298"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">genial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">5400</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, main <span class="op">=</span><span class="st">"Figure 3. Distribution des hommes géniaux, dignes d'intérêt"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-159-1.png" width="672"></div>
<p>Le problème est que les jeunes hommes qui ne méritent pas l’intérêt de notre jeune femme n’ont pas écrit sur leur front qu’ils ne sont pas dignes d’intérêt.
Bien sûr, certains vont être éliminés très rapidement (“hey mademoiselle, t’as un 06 ?”), mais pour certains, les choses sont moins clairs. On peut raisonnablement penser qu’une personne qui n’est pas un prince charmant est tout de même en mesure d’intéresser notre jeune personne pendant une cinquantaine de minutes, c’est-à-dire 3000 secondes. La distribution des hommes qui sont moins dignes d’intérêt est représentée en Figure 4.</p>
<div class="sourceCode" id="cb299"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">banal</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">3000</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, main<span class="op">=</span><span class="st">"Figure 4. Distribution des hommes peu dignes d'intérêt"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-160-1.png" width="672"></div>
<p>Les choses se compliquent quand il y a une incertitude sur l’issue du test (quand on rencontre une personne, on n’a pas la certitude absolue qu’il s’agit de la personne de notre vie). La raison est due au fait que la zone de délimitation est floue et que la ditribution des hommes géniaux se superpose à la distribution des hommes ayant moins d’intérêt, comme vous pouvez le constater dans la Figure 5.</p>
<div class="sourceCode" id="cb300"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Histogrammes non-imprimés :</span></span>
<span><span class="va">bp1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co"># 20 classes...</span></span>
<span><span class="va">bp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co">#</span></span>
<span></span>
<span><span class="co">## Calcul de minima/maxima :</span></span>
<span><span class="va">hlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">breaks</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">vlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">counts</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">counts</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Couleurs de remplissage, dont une avec ajout de transparence :</span></span>
<span><span class="va">histcol</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/col2rgb.html">col2rgb</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"orangered2"</span>, <span class="st">"lightblue"</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fl">255</span>,</span>
<span>                              alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>, <span class="co"># Première couleur opaque, 50% de transparence pour la seconde.</span></span>
<span>                              <span class="fl">2</span>, <span class="va">as.list</span><span class="op">)</span>,</span>
<span>                             <span class="va">do.call</span>, what <span class="op">=</span> <span class="va">rgb</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Création du graphique :</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, border<span class="op">=</span><span class="st">"darkred"</span>, xlim<span class="op">=</span><span class="va">hlims</span>, ylim<span class="op">=</span><span class="va">vlims</span>,</span>
<span>     nclass<span class="op">=</span><span class="fl">20</span>,                         <span class="co"># 20 classes...</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, main<span class="op">=</span><span class="st">"Figure 5. Fréquence en fonction du type d'hommes"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, border<span class="op">=</span><span class="st">"darkblue"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>     breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, to<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, by<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>, <span class="co"># largeur de classes égale à celle du précédent graphique</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>      <span class="co"># Couleur transparente (en sur-impression).</span></span>
<span><span class="va">seuil</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">3000</span>,<span class="fl">1000</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v<span class="op">=</span><span class="va">seuil</span>,lwd<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x<span class="op">=</span><span class="fl">3000</span>, y<span class="op">=</span><span class="fl">200</span>, <span class="st">"banal"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x<span class="op">=</span><span class="fl">6000</span>, y<span class="op">=</span><span class="fl">200</span>, <span class="st">"génial"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-161-1.png" width="672"></div>
<p>Dans cet exemple, les hommes qui n’arriveront pas à intéresser notre jeune femme pendant au moins <span class="math inline">\(4960\)</span> secondes seront considérés comme banal alors que ceux qui arriveront à intéresser la jeune femme plus longtemps que ce seuil seront considérés comme géniaux.</p>
<p>Dans cet exemple, une partie des hommes qui appartiennent au groupe des hommes banals arrivent à passer le seuil à partir duquel on les conidère comme géniaux. Vous les connaissez, ce sont les beaux parleurs : vous croyez en leurs doux mots, vous leur proposez votre numéro … et ils ne vous rappellent pas.</p>
<p>A l’inverse, une part importante des hommes qui appartiennent au groupe des princes charmants se voient affublés de l’étiquette “banal” car ils sont plus timides, moins diserts…</p>
<p>En d’autres termes, dans avec un test statistique, il y a deux moyens d’avoir raison et deux moyens de se tromper.
Lorsque vous considérez un homme banal comme banal, cela signifie que vous tolérez à raison l’hypothèse nulle selon laquelle il n’est pas significativement différent. Dans ce cas, on parle d’intervalle de confiance. Il est généralement à 95%. Cet intervalle de confiance signifie que, si on connait les paramètres d’une population, on peut estimer un intervalle à l’intérieur duquel 95% des estimations de ce paramètre se situeront.</p>
<p>Le complément de l’intervalle de confiance est l’erreur de 1e espèce, appelée <span class="math inline">\(\alpha\)</span>. Elle est habituellement de 5%, et dans notre exemple, ils sont représentés par les beaux parleurs.</p>
<p>Lorsqu’on considère un homme comme appartenant à la catégorie des princes charmants et qu’il se trouve qu’il est effectivement un prince charmant, il s’agit de la seconde manière d’avoir raison. Cette condition consiste à rejeter à raison l’hypothèse nulle. On parle dans ce cas de puissance statistique.</p>
<p>Le complèment de la puissance statistique est l’erreur de seconde espèce, appelée <span class="math inline">\(\beta\)</span>.</p>
<p>Ces deux manières d’avoir raison et ces deux manières d’avoir tort sont résumées dans le Tableau <a href="#tab:ICpuissance"><strong>??</strong></a>.</p>
<p><br></p>
<p>1 = IC + alpha</p>
<p>1 = bêta + puissance</p>
<p>Dans notre exemple, les valeurs pour chacun des paramètres sont :</p>
<pre><code>## 
## Attachement du package : 'kableExtra'</code></pre>
<pre><code>## Les objets suivants sont masqués depuis 'package:flextable':
## 
##     as_image, footnote</code></pre>
<pre><code>## L'objet suivant est masqué depuis 'package:dplyr':
## 
##     group_rows</code></pre>
<p>Dans cet exemple, on se posait la question à un niveau individuel. Cependant, la plupart du temps, on se pose la questiion au niveau du groupe (i.e., est-ce que tel groupe se distingue de tel autre groupe ?).</p>
<p>Pour comprendre la manière dont cela fonctionne au niveau du groupe, il faut comprendre deux notions essentielles en statistiques : la notion d’échantillonnage et le théorème central limit.</p>
<p>La manière la plus simple de comprendre ces deux notions consiste à en fait la démonstration par un exemple.</p>
<p>On va commencer par créer une population artificielle dont la distribution est plate. On obtient ce type de distribution en faisant par exemple une séquence de 1 à 10 000.</p>
<div class="sourceCode" id="cb304"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pop</span><span class="op">&lt;-</span><span class="fl">1</span><span class="op">:</span><span class="fl">10000</span></span></code></pre></div>
<p>On peut obtenir la distribution de cette population à l’aide la fonction <code>hist</code>.</p>
<div class="sourceCode" id="cb305"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">pop</span>, main <span class="op">=</span> <span class="st">"Figure 6. Représentation de la population créée"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-163-1.png" width="672"></div>
<p>Deux constats doivent être dressés :
1) la distribution est plate ;
2) les valeurs vont de 1 à 10 000.</p>
<p>La moyenne de cette distribution vaut <span class="math inline">\(5000.5\)</span> et l’écart-type vaut <span class="math inline">\(2886.8956799\)</span>. Si on prend un échantillon de 50 personnes au hasard dans cette population grâce à la fonction <code>sample</code>, on va se rendre compte que la moyenne de cet échantillon ne sera pas exactement égal à la moyenne de la population.</p>
<div class="sourceCode" id="cb306"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">pop</span>,<span class="fl">50</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">M_ech</span></span>
<span><span class="va">M_ech</span></span></code></pre></div>
<pre><code>##  [1] 3594  334 7295 7434 7762 1804 4887 3000 8094  426 4731 5945 9980 9351 6801
## [16] 3719 4698 9033 9953 8559 2007 4169 7474 2055 1514 9301 5394 7220 2793 6872
## [31]  902 9422 5686 8958 8043 4125 1089  507 9244 7090 6206 5067 1040 3199 1304
## [46] 9603 5950 2568 8578 3577</code></pre>
<div class="sourceCode" id="cb308"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">M_ech</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 5367.14</code></pre>
<p>Si on répète un grand nombre de fois cette opération, on va obtenir systématiquement une moyenne différente, quelque fois très proche de la moyenne de la population, d’autres fois plus éloignée.
La manière dont les moyennes d’échantillon se distribuent autour de la vraie moyenne (i.e., la paramètre) est ce qu’on appelle la distribution d’échantillonnage
L’appli sur le lien suivant permet de voir comment la distribution des moyennes d’échantillons :
<a href="https://ihstevenson.shinyapps.io/sample_means/" class="uri">https://ihstevenson.shinyapps.io/sample_means/</a></p>
<p>Dans notre cas, nous allons faire une boucle grâce à la fonction <code>for</code> qui va permettre d’obtenir 100 000 moyennes d’échantillons que nous allons stocker dans un vecteur, appelé M_ech.</p>
<div class="sourceCode" id="cb310"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">99999</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">pop</span>,<span class="fl">50</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">M_ech2</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">M_ech</span>, <span class="va">M_ech2</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">M_ech</span></span>
<span>  <span class="op">}</span></span></code></pre></div>
<p>Nous pouvon faire une présentation graphique de la manière dont les moyennes d’échantillons se répartissent autour de la moyenne de la population grâce à la fonction <code>hist</code>.</p>
<div class="sourceCode" id="cb311"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">M_ech</span>, main<span class="op">=</span><span class="st">"Figure 7.Représentation graphique de la distribution d'échantillonnage"</span>, xlab<span class="op">=</span><span class="st">"distribution des moyennes d'échantillon"</span>, </span>
<span>     xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fl">3500</span>,<span class="fl">6500</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-166-1.png" width="672"></div>
<div class="sourceCode" id="cb312"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">M_ech</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 5002.093</code></pre>
<div class="sourceCode" id="cb314"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">M_ech</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 411.2281</code></pre>
<p>A présent, 3 constats doivent être faits :</p>
<ol style="list-style-type: decimal">
<li><p>La distribution n’est plus plate ;</p></li>
<li><p>La moyenne des moyennes vaut <span class="math inline">\(5002\)</span> ;</p></li>
<li><p>L’écart-type de la distribution des moyennes d’échantillon vaut <span class="math inline">\(411\)</span>.</p></li>
</ol>
<p>Pour le premier point, ce phénomène s’explique par le théorème centrale limite, selon lequel, indépendamment de la distribution initiale des données, si l’échantillon est suffisamment grand (la notion de suffisamment grand étant relative), la distribution des moyennes d’échantillon suivra une distribution normale.
Ce théorème explique un argument qu’on observe régulièrement concernant le non respect de la normalité de la distribution : ce n’est pas grave parce que, comme mon échantillon est suffisamment grand, la distribution d’échantillonnage suit une distribution normale grâce au théorème central limit.
Cet argument n’est qu’à moitié correct : il ne tiendrait pas si une distribution fortement asymétrique avait été utilisée au lieu d’une distribution plate.</p>
<p>Pour le second point, cela illustre que le fait de répéter un grand nombre de fois une expérimentation permet d’avoir une estimation relativement précise du paramètre de la population.</p>
<p>Enfin, le 3e point amène à comprendre la notion d’erreur type. L’erreur-type, standard error (se) en anglais, est l’écart-type divisé par la racine carrée de la taille de l’échantillon.</p>
<p><span class="math display">\[se = \frac{s}{\sqrt{n}}\]</span>
Et nous constatons que l’erreur-type simulé est assez proche de l’erreur-type estimée de manière théorique.</p>
<div class="sourceCode" id="cb316"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">pop</span><span class="op">)</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span></span></code></pre></div>
<pre><code>## [1] 408.2687</code></pre>
<p>Ce principe est donc à la base d’un test comme le t de Student comparaison à une norme. En effet, la formule du t de Student comparaison à une norme est la suivante :</p>
<p><span class="math display">\[t=\frac{\bar{x}-\mu}{ \frac{s}{\sqrt{n}}}\]</span>
où <span class="math inline">\(\bar{x}\)</span> correspond à la moyenne de l’échantillon, <span class="math inline">\(\mu\)</span> correspond à la moyenne de la population, s correspond à l’écart-type de l’échantillon et n correspond à la taille de l’échantillon.
Si on reprend la formule du z, on identifie que c’est exactement la même formule avec un échantillon d’une personne : la moyenne d’une observation est cette observation, et faire la racine de 1 vaut 1.</p>
<p><span class="math display">\[z=\frac{x_i-\mu}{\frac{s}{\sqrt{1}}}=\frac{x_i-\mu}{s}\]</span></p>
<p>Ainsi, quand on réalise un test statistique, un probabilité va être associée à la valeur de la statistique. Si cette probabilité vaut 0.70, cela signifie que, sur la base d’un tirage aléatoire dans une population initiale, 70% des échantillons vont présenter une différence égale ou plus grande que la différence observée. Comme la probabilité est en l’occurrence élevée, il est tout à fait possible que la différence observée soit due à l’erreur (en termes d’estimation) d’échantillonnage. On ne peut donc pas rejeter l’hypothèse nulle avec un risque de se tromper suffisamment faible.</p>
<p>Si vous avez suivi le raisonnement, vous devriez avoir compris que 5% des moyennes d’échantillons (i.e., 500) se répartiront de manière équitable au-dessous du percentile 2.5 et au-dessus du percentile 97.5 évalués estimé sur base d’une distribution normale.</p>
<p>La fonction <code>qnorm</code> permet de tester cela.</p>
<div class="sourceCode" id="cb318"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lower</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">pop</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.025</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">pop</span><span class="op">)</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span> <span class="co"># fixe la limite basse</span></span>
<span><span class="va">upper</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">pop</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">pop</span><span class="op">)</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span> <span class="co"># fixe la limite haute</span></span>
<span><span class="va">n.low</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">M_ech</span><span class="op">&lt;</span><span class="va">lower</span><span class="op">)</span><span class="op">)</span> <span class="co"># nombre en dessous de la limite inférieure</span></span>
<span><span class="va">n.high</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">M_ech</span><span class="op">&gt;</span><span class="va">upper</span><span class="op">)</span><span class="op">)</span> <span class="co"># nombre en dessous de la limite supérieure</span></span>
<span><span class="va">n.low</span></span></code></pre></div>
<pre><code>## [1] 2350</code></pre>
<div class="sourceCode" id="cb320"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n.high</span></span></code></pre></div>
<pre><code>## [1] 2495</code></pre>
<div class="sourceCode" id="cb322"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n.low</span><span class="op">+</span><span class="va">n.high</span></span></code></pre></div>
<pre><code>## [1] 4845</code></pre>
<p>On constate qu’il y a effectivement environ 500 échantillons sur 10 000 qui ont dépassé le seuil de significativité, ce qui représente le pourcentage d’erreur de première espèce que nous admettrons.</p>
<p>Donc, bien que ces 5% d’échantillons qui se trouvent aux deux extrêmes appartiennent à la population des que nous avons créée, on va considérer (à tort) qu’ils sont significativement différents de la population créée.</p>
</div>
</div>
<div id="lien-entre-la-taille-deffet-et-la-significativité" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Lien entre la taille d’effet et la significativité<a class="anchor" aria-label="anchor" href="#lien-entre-la-taille-deffet-et-la-significativit%C3%A9"><i class="fas fa-link"></i></a>
</h2>
<p>Dans l’exemple que nous avons utilisé, les hommes géniaux étaient intéressants pendant 5400 secondes alors que les hommes banals étaient intéressants pendant 3000 secondes. Comme l’écart-type était de 1000, cela signifie que la moyenne des hommes banals et celle des hommes géniaux sont à 2.4 écart-types l’une de l’autre. En effet, on l’obtient de la manière suivante :</p>
<p><span class="math display">\[d_{Cohen}=\frac{5400-3000}{1000}=2.4\]</span></p>
<p>Cette valeur de 2.4 est ce qu’on appelle le d de Cohen. Il correspond à la taille d’effet pour une comparaison de deux moyennes. Pour chaque test statistique (ou pratiquement), il existe une taille d’effet qui lui est propre.
Pour Cohen (1988), une taille d’effet de 0.2 est une petit taille, une taille d’effet de 0.5 est une taille d’effet moyenne et une taille d’effet de 0.8 est une grande taille d’effet. Il faut tout de même avoir conscience que ces limites sont arbitraires et qu’elles dépendant grandement du domaine scientifique dans lequel on travaille : les tailles d’effet sont généralement plus faibles en psychologie qu’en biologie. Néanmoins, on comprendre qu’avec une taille d’effet de 2.4, la taille d’effet est colossale et qu’il est plutôt rare d’observer de telles tailles d’effets dans la réalité.</p>
<p>Pour prendre un exemple plus réaliste, considérons à présent que les hommes banals sont intéressants pendant 5000 secondes alors que les hommes géniaux sont intéressants pendant 5400 secondes, la taille d’effet est à présent de 0.4 et la courbe des hommes géniaux et des hommes banals vont se recouvrir de la manière suivante :</p>
<div class="sourceCode" id="cb324"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">banal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">5000</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">genial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">5400</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Histogrammes non-imprimés :</span></span>
<span><span class="va">bp1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co"># 20 classes...</span></span>
<span><span class="va">bp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co">#</span></span>
<span></span>
<span><span class="co">## Calcul de minima/maxima :</span></span>
<span><span class="va">hlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">breaks</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">vlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">counts</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">counts</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span></span>
<span><span class="co">## Couleurs de remplissage, dont une avec ajout de transparence :</span></span>
<span><span class="va">histcol</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/col2rgb.html">col2rgb</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"orangered2"</span>, <span class="st">"lightblue"</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fl">255</span>,</span>
<span>                              alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>, <span class="co"># Première couleur opaque, 50% de transparence pour la seconde.</span></span>
<span>                        <span class="fl">2</span>, <span class="va">as.list</span><span class="op">)</span>,</span>
<span>                  <span class="va">do.call</span>, what <span class="op">=</span> <span class="va">rgb</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Création du graphique :</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, border<span class="op">=</span><span class="st">"darkred"</span>, xlim<span class="op">=</span><span class="va">hlims</span>, ylim<span class="op">=</span><span class="va">vlims</span>,</span>
<span>     nclass<span class="op">=</span><span class="fl">20</span>,                         <span class="co"># 20 classes...</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, main<span class="op">=</span><span class="st">"fréquence en fonction du type d'hommes"</span>, xlab<span class="op">=</span><span class="st">"banal et génial"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, border<span class="op">=</span><span class="st">"darkblue"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>     breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, to<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, by<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>, <span class="co"># ...largeur de classes égale à celle</span></span>
<span>                                                                           <span class="co"># du précédent graphique</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>      <span class="co"># Couleur transparente (en sur-impression).</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-169-1.png" width="672"></div>
<p>On constate que la superposition entre les deux courbes est très important et qu’il est difficile de distinguer les hommes géniaux des hommes banals.</p>
<p>De manière intéressante, si au lieu de s’intéresser à une personne particulière, on fait l’hypothèse que les princes charmants trainent ensemble et que les hommes banals trainent entre eux, mais ils ne se mélangent, vous pourriez rechercher des groupes d’une dizaine d’homme et, dans ce cas, la superposition des deux courbes serait moins importante.</p>
<div class="sourceCode" id="cb325"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">banal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">5000</span>, <span class="fl">1000</span><span class="op">/</span><span class="fl">10</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">genial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">5400</span>, <span class="fl">1000</span><span class="op">/</span><span class="fl">10</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Histogrammes non-imprimés :</span></span>
<span><span class="va">bp1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co"># 20 classes...</span></span>
<span><span class="va">bp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co">#</span></span>
<span></span>
<span><span class="co">## Calcul de minima/maxima :</span></span>
<span><span class="va">hlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">breaks</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">vlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">counts</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">counts</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span></span>
<span><span class="co">## Couleurs de remplissage, dont une avec ajout de transparence :</span></span>
<span><span class="va">histcol</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/col2rgb.html">col2rgb</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"orangered2"</span>, <span class="st">"lightblue"</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fl">255</span>,</span>
<span>                              alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>, <span class="co"># Première couleur opaque, 50% de transparence pour la seconde.</span></span>
<span>                        <span class="fl">2</span>, <span class="va">as.list</span><span class="op">)</span>,</span>
<span>                  <span class="va">do.call</span>, what <span class="op">=</span> <span class="va">rgb</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Création du graphique :</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, border<span class="op">=</span><span class="st">"darkred"</span>, xlim<span class="op">=</span><span class="va">hlims</span>, ylim<span class="op">=</span><span class="va">vlims</span>,</span>
<span>     nclass<span class="op">=</span><span class="fl">20</span>,                         <span class="co"># 20 classes...</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, main<span class="op">=</span><span class="st">"fréquence en fonction du type d'hommes"</span>, xlab<span class="op">=</span><span class="st">"banal et génial"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, border<span class="op">=</span><span class="st">"darkblue"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>     breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, to<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, by<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>, <span class="co"># ...largeur de classes égale à celle</span></span>
<span>                                                                           <span class="co"># du précédent graphique</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>      <span class="co"># Couleur transparente (en sur-impression).</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-170-1.png" width="672"></div>
<p>Le même raisonnement vaudait pour un échantillon de 50 personnes, les deux courbes se superposeraient encore</p>
</div>
<div id="quand-cest-encore-moins-évident" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Quand c’est encore moins évident?<a class="anchor" aria-label="anchor" href="#quand-cest-encore-moins-%C3%A9vident"><i class="fas fa-link"></i></a>
</h2>
<p>Superposition des courbes quand on prend un échantillon de 50 personnes</p>
<div class="sourceCode" id="cb326"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">banal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">5000</span>, <span class="fl">1000</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">genial</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">5400</span>, <span class="fl">1000</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Histogrammes non-imprimés :</span></span>
<span><span class="va">bp1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co"># 20 classes...</span></span>
<span><span class="va">bp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, plot<span class="op">=</span><span class="cn">FALSE</span>, nclass<span class="op">=</span><span class="fl">20</span><span class="op">)</span>  <span class="co">#</span></span>
<span></span>
<span><span class="co">## Calcul de minima/maxima :</span></span>
<span><span class="va">hlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">breaks</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">vlims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">counts</span>, <span class="va">bp2</span><span class="op">$</span><span class="va">counts</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Couleurs de remplissage, dont une avec ajout de transparence :</span></span>
<span><span class="va">histcol</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/col2rgb.html">col2rgb</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"orangered2"</span>, <span class="st">"lightblue"</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fl">255</span>,</span>
<span>                              alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>, <span class="co"># Première couleur opaque, 50% de transparence pour la seconde.</span></span>
<span>                        <span class="fl">2</span>, <span class="va">as.list</span><span class="op">)</span>,</span>
<span>                  <span class="va">do.call</span>, what <span class="op">=</span> <span class="va">rgb</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Création du graphique :</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">banal</span>, border<span class="op">=</span><span class="st">"darkred"</span>, xlim<span class="op">=</span><span class="va">hlims</span>, ylim<span class="op">=</span><span class="va">vlims</span>,</span>
<span>     nclass<span class="op">=</span><span class="fl">20</span>,                         <span class="co"># 20 classes...</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, main<span class="op">=</span><span class="st">"fréquence en fonction du type d'hommes"</span>, xlab<span class="op">=</span><span class="st">"banal et génial"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">genial</span>, border<span class="op">=</span><span class="st">"darkblue"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>     breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, to<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">hlims</span><span class="op">)</span>, by<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="va">bp1</span><span class="op">$</span><span class="va">breaks</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>, <span class="co"># ...largeur de classes égale à celle</span></span>
<span>                                                                           <span class="co"># du précédent graphique</span></span>
<span>     col<span class="op">=</span><span class="va">histcol</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>      <span class="co"># Couleur transparente (en sur-impression).</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-171-1.png" width="672"></div>
<p>Ce qui est illustré dans ce qui précède est la notion de puissance statistique. Plus les courbes se superposent, et moins la puissance est élevée. A l’inverse, moins elles se superposent plus la puissance est élevée. Les facteurs qui ont un impact sur la puissance statistique sont : la taille de l’effet et la taille de l’échantillon. On pourrait rajouter certains paramètres expérimentaux comme être en intra participant, c’est-à-dire avoir les mêmes personnes/objets/animaux… pour l’ensemble des mesures, ou encore contrôler l’effet de certains effets parasites à l’aide de covariables.</p>
<p>La puissance statistique doit être au minimum de 0.80 (Cohen, 1988), mais les recommendations actuelles tendent à l’augmenter à 0.95 (Lakens, 2013). Cependant, atteindre une puissance de 0.95 entraîne une inflation du nombre de participants (ou de sujet, au sens large - bien que ce terme n’est pas très élégant) qu’il faut recruter, ce qui n’est pas toujours possible dans les études.</p>
<p>Pour notre exemple, on peut fixer la puissance à 0.80. Avec un échantillon pour lequel on s’attend à ce que la moyenne soit de 5000 et un autre pour lequel on s’attend à ce que la moyenne soit à 5400, et un écart-type de 1000, on peut obtenir la puissance à l’aide de la fonction <code>pwr.t.test</code> du package ‘pwr’.</p>
<div class="sourceCode" id="cb327"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/heliosdrm/pwr">pwr</a></span><span class="op">)</span></span>
<span><span class="va">d</span><span class="op">&lt;-</span><span class="op">(</span><span class="fl">5000</span><span class="op">-</span><span class="fl">5400</span><span class="op">)</span><span class="op">/</span><span class="fl">1000</span></span>
<span><span class="va">d</span></span></code></pre></div>
<pre><code>FALSE [1] -0.4</code></pre>
<div class="sourceCode" id="cb329"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/pwr/man/pwr.t.test.html">pwr.t.test</a></span><span class="op">(</span>d<span class="op">=</span><span class="va">d</span>,sig.level <span class="op">=</span> <span class="fl">0.05</span>, power<span class="op">=</span><span class="fl">0.80</span>, type<span class="op">=</span><span class="st">"two.sample"</span>, alternative<span class="op">=</span><span class="st">"two.sided"</span><span class="op">)</span></span></code></pre></div>
<pre><code>FALSE 
FALSE      Two-sample t test power calculation 
FALSE 
FALSE               n = 99.08032
FALSE               d = 0.4
FALSE       sig.level = 0.05
FALSE           power = 0.8
FALSE     alternative = two.sided
FALSE 
FALSE NOTE: n is number in *each* group</code></pre>
<p>Il faut donc un échantillon de 99 personnes par groupe pour que la puissance statistique soit de 0.80.</p>
<p>Cependant, il faut avoir conscience qu’il existe deux différences majeures entre mon exemple pédagogique et la réalité :</p>
<ol style="list-style-type: decimal">
<li><p>Dans la réalité, on ne connait pas la valeur réelle des moyennes de chaque modalité qu’on veut comparer.</p></li>
<li><p>Dans la réalité, il faut calculer la puissance statistique a priori, c’est-à-dire avant le début du recueil de données.</p></li>
</ol>
<p>Normalement, vous devriez avoir identifié un problème : dans la réalité, vous ne connaissez pas les moyennes des paramètres (ni l’écart-type) alors comment pourriez-vous calculer la puissance a priori ? Il existe plusieurs possibilités :</p>
<ol style="list-style-type: decimal">
<li><p>vous vous appuyez sur la littérature scientifique, les champs de recherche proche de celui investigué pour déterminer la taille d’effet habituellement observée.</p></li>
<li><p>vous réalisez une étude pilote pour estimer la taille de l’échantillon nécessaire, mais les données obtenues par l’étude pilote ne doivent pas faire partie du jeu de données final.</p></li>
<li><p>vous estimez la taille d’effet minimum que vous désirez mettre en évidence dans l’étude et vous fixez la puissance en fonction de cette taille d’effet minimum. Par exemple, si vous voulez tester l’effet d’un médicament, et que vous savez que l’effet placebo explique 5% de la variance, alors vous pourriez décider que votre médicament pour être utile doit avoir un effet deux fois plus important que l’effet placebo, c’est-à-dire expliquer 10% de la variance.</p></li>
</ol>
</div>
<div id="en-synthèse" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> En synthèse<a class="anchor" aria-label="anchor" href="#en-synth%C3%A8se"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p>les tests statistiques testent une hypothèse d’absence de différence</p></li>
<li><p>La probabilité fournie par un test est la probabilité d’observer la différence en raison des variations aléatoires dues à la distribution d’échantillonnage.</p></li>
<li><p>Si la probabilité est faible, cela signifie qu’il est improbable que la différence soit dû au hasard et on l’attribuera alors à l’effet de la manipulation expérimental.</p></li>
<li><p>Dans ce dernier cas, on dit qu’on rejette l’hypothèse nulle.</p></li>
<li><p>On peut commettre deux types d’erreurs : l’erreur de 1e espèce et de 2e espèce.</p></li>
<li><p>Habituellement, on fixe l’erreur de 1e espèce à 5% et l’erreur de 2e espèce au maximum à 20%</p></li>
<li><p>Même si on a une population qui n’est pas distribuée normalement, la distribution d’échantillonnage suivra la loi normale si la distribution initiale ne présente pas une asymétrie trop importante.</p></li>
<li><p>On diminue l’erreur de type II en augmentant la taille de l’échantillon</p></li>
<li><p>Il faut connaître la taille de l’effet pour calculer la puissance a priori.</p></li>
<li><p>Deux facteurs influencent la puissance : la taille de l’effet et la taille de l’échantillon</p></li>
</ul>
<div id="une-approche-plus-formelle" class="section level3" number="9.5.1">
<h3>
<span class="header-section-number">9.5.1</span> Une approche plus formelle<a class="anchor" aria-label="anchor" href="#une-approche-plus-formelle"><i class="fas fa-link"></i></a>
</h3>
<div id="la-crise-de-reproductibilité-et-le-p-hacking." class="section level4" number="9.5.1.1">
<h4>
<span class="header-section-number">9.5.1.1</span> La crise de reproductibilité et le p hacking.<a class="anchor" aria-label="anchor" href="#la-crise-de-reproductibilit%C3%A9-et-le-p-hacking."><i class="fas fa-link"></i></a>
</h4>
<p>Dans tous les domaines scientifiques, il est nécessaire de publier des articles, et dans les entreprises, d’avoir des résultats intéressants.</p>
<p>Au niveau universitaire par exemple, publier permet d’avoir un poste, des promotions, des primes, des financements. Quand on a des financements, il faut pouvoir les justifier, expliquer ce qu’on a fait de ces financements. Généralement, on résume la nécessité de publier pour les chercheurs par un adage : “publish or perish!”.</p>
<p>Au niveau privé, montrer qu’un médicament est efficace permet de le commercialiser, montrer qu’un engrais n’est pas dangereux permet de le commercialiser…</p>
<p>Bref, tant au niveau public que dans le privé, les enjeux sont énormes, et quand les enjeux sont énormes, les dérives commencent à apparaître.</p>
<p>Pour comprendre la cause de ces dérives, il est nécessaire de savoir ce qu’est un résultit dit “positif”. Il s’agit des études pour lesquels les données corroborent l’hypothèse par la présence de résultats significatifs. Ce sont ces résultats qui sont essentiellement publiés en science.</p>
<p>En psychologie, par exemple, Fanelli (2010) souligne que 90% des études publiées sont des réultats positifs. Ce nombres d’études avec des résultats positifs suit une tendance constante depuis les année 1990. En effet, dans une étude de 2011, Fanelli montre que la publication de résultats positifs a augmenté de 22% depuis les années 1990. On comprend dès lors aisément pourquoi il faut des résultats positifs et que cela amène à des comprotements douteux.</p>
<p>Un des comportements douteux est évidemment la fabrication de données, ce qui a été largement médiatisée par l’affaire Stapel, un psychologue social, qui avait fabriqué les résultats de plusieurs dizaines de ses articles. On pourrait penser que ce phénomène est plutôt rare, mais c’est loin d’être certain. En effet, Fanelli (2009), encore lui, a posé à des chercheurs deux questions :</p>
<ul>
<li><p>Avez-vous déjà trafiqué vos données ?</p></li>
<li><p>Avez-vous déjà adopté une pratique douteuse (il n’est pas nécesaire de dévolopper ici les différentes pratiques douteuses) ?</p></li>
</ul>
<p>Ce qui est intéressant, c’est que, sur le panel de chercheurs, la plupart indique s’être toujours comporté de manière intègre, mais que les 3/4 connaissent un collègue qui a adopté une pratique douteuse, et qu’un tiers des chercheurs connaissent même quelqu’un qui a fabriqué ou falsifié ses données.</p>
<p><small> Table 2. Résultats obtenus par Faneli (2009) </small></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="31%">
<col width="39%">
<col width="28%">
</colgroup>
<thead><tr class="header">
<th></th>
<th align="center">Fabrication/modification</th>
<th align="center">Autres pratiques</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>J’ai pratiqué</td>
<td align="center">1,97%</td>
<td align="center">14,12%</td>
</tr>
<tr class="even">
<td>Je connais quelqu’un</td>
<td align="center">33,7%</td>
<td align="center">72%</td>
</tr>
</tbody>
</table></div>
<p>Parmi les pratiques douteuses que la plupart des personnes n’identifient même pas comme problématique, il y a le p-hacking.</p>
</div>
<div id="le-p-hacking." class="section level4" number="9.5.1.2">
<h4>
<span class="header-section-number">9.5.1.2</span> Le p hacking.<a class="anchor" aria-label="anchor" href="#le-p-hacking."><i class="fas fa-link"></i></a>
</h4>
<p>Le p-hacking consiste à analyser les données qu’on a obtenu de différentes manières, en ajoutant parfois des observations, en supprimant des observations dites “outliers”, en ajoutant des covariables, ou simplement en prenant un grand nombre de mesures et en ne présentant les résultats que d’une minorité de ces mesures.</p>
<p>Pour comprendre le p hacking, il faut comprendre un principe statistique essentiel : la multiplication de l’erreur de 1e espèce.</p>
<p>Ce principe se résume à une phrase : plus vous faites d’analyses, plus vous augmentez le risque d’obtenir un effet significatif alors que vous ne devriez pas en avoir un.</p>
<p>Pour l’illustrer, nous allons reprendre l’exemple que nous avions réalisé plus haut pour montrer la distribution d’échantillonnnage. La simulation montrait que 5% des échantillons étaient considérés comme dépassant le seuil de significativité.
Pour reprendre le raisonnement complet, le t de Student comparaison à une norme est obtenu à l’aide la formule suivante :</p>
<div class="centered">
<p><span class="math display">\[t= \frac{\bar{x}-\mu}{\frac{\sigma}{\sqrt n}}\]</span></p>
</div>
<p>On peut obtenir le seuil précis de significativité grâve à la fonction <cdoe>qt. Dans cette fonction, il faut préciser le seuil unilatéral (i.e., 0.025) et les degrés de liberté (ddl). Pour le t comparaison à une norme, les ddl valent la taille de l’échantillon -1. Comme nous avons pris des échantillons de 50 personnes, les ddl valent 49.</cdoe></p>
<div class="sourceCode" id="cb331"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">49</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] -2.009575</code></pre>
<p>Nous pouvons à présent calculer le t de Student pour l’ensemble des moyennes d’échantillons que nous avions obtenues pour illustrer la distribution d’échantillonnage. Le code ci-dessous fournit les t premiers t</p>
<div class="sourceCode" id="cb333"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">t</span><span class="op">&lt;-</span><span class="op">(</span><span class="va">M_ech</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">pop</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">pop</span><span class="op">)</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<p>Le code ci-dessous fournit les 10 premiers t obtenus pour les 10 premières moyennes d’échantillons.</p>
<div class="sourceCode" id="cb334"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">M_ech</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></span></code></pre></div>
<pre><code>##  [1] 3594  334 7295 7434 7762 1804 4887 3000 8094  426</code></pre>
<div class="sourceCode" id="cb336"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">t</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  [1]  -3.45 -11.43   5.62   5.96   6.76  -7.83  -0.28  -4.90   7.58 -11.20</code></pre>
<p>On peut comptabiliser le nombre de t qui amènent à rejter à tort l’hypothèse nulle (erreur de première espèce).</p>
<div class="sourceCode" id="cb338"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://had.co.nz/plyr">plyr</a></span><span class="op">)</span></span>
<span><span class="va">n</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/plyr/man/count.html">count</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">t</span><span class="op">&gt;</span><span class="fl">2.009575</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">n</span></span></code></pre></div>
<pre><code>##   x  freq
## 1 0 97822
## 2 1  2227</code></pre>
<div class="sourceCode" id="cb340"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">t</span><span class="op">)</span></span></code></pre></div>
<pre><code>##              x       freq
## 1 0.000000e+00 0.97774091
## 2 9.995102e-06 0.02225909</code></pre>
<p>En l’occurrence, l’erreur de 1e espèce est d’environ 5% comme attendu.</p>
<p>Imaginons à présent que nous faisions deux analyses. On peut le simuler avec la fonctino <code>sample</code> qui va échantilloner deux t dans la liste des t disponibles.</p>
<div class="sourceCode" id="cb342"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">deux</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">t</span>, <span class="fl">2</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span></span>
<span><span class="va">deux</span></span></code></pre></div>
<pre><code>## [1] -0.9578006 -0.2075594</code></pre>
<p>Si nous répétons un grand nombre de fois (1000 par exemple) l’opération pour 2 échantillons, le nombre de situations où au moins un des t est significatif serait bien plus élevé que 5%. Le code ci-desous crée une boucle qui permet de faire cette simulation.</p>
<div class="sourceCode" id="cb344"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span><span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">t</span>, <span class="fl">2</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">deuxb</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">deux</span>, <span class="va">deuxb</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">deux</span><span class="op">}</span></span>
<span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">deux</span><span class="op">)</span><span class="op">&gt;</span><span class="fl">2.009575</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">sig</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">sig</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">n_sig2</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plyr/man/count.html">count</a></span><span class="op">(</span><span class="va">n_sig2</span><span class="op">&gt;</span><span class="fl">0</span><span class="op">)</span><span class="op">-&gt;</span> <span class="va">n_sig2</span></span>
<span><span class="va">n_sig2</span></span></code></pre></div>
<pre><code>##       x freq
## 1 FALSE  926
## 2  TRUE   75</code></pre>
<p>Dans ce cas, l’erreur de première espèce serait de <span class="math inline">\(7.5\)</span> pourcents, donc bien supérieur au 5% intialement accepté.</p>
<p>Ce phénomène est accenté lorsqu’on fait encore plus d’analyses, comme 5 ou 10 analyses.</p>
<div class="sourceCode" id="cb346"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">t</span>, <span class="fl">5</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">cinq</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span><span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">t</span>, <span class="fl">5</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">cinqb</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">cinq</span>, <span class="va">cinqb</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">cinq</span><span class="op">}</span></span>
<span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">cinq</span><span class="op">)</span><span class="op">&gt;</span><span class="fl">2.009575</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">sig</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">sig</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">n_sig5</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plyr/man/count.html">count</a></span><span class="op">(</span><span class="va">n_sig5</span><span class="op">&gt;</span><span class="fl">0</span><span class="op">)</span><span class="op">-&gt;</span> <span class="va">n_sig5</span></span>
<span><span class="va">n_sig5</span></span></code></pre></div>
<pre><code>##       x freq
## 1 FALSE  793
## 2  TRUE  208</code></pre>
<p>En effet, le taux d’erreur de 1e espèce pour 5 analyses est de <span class="math inline">\(20.8\)</span> pourcents.</p>
<div class="sourceCode" id="cb348"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">t</span>, <span class="fl">10</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">dix</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span><span class="op">{</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">t</span>, <span class="fl">10</span>, replace<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">dixb</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">dix</span>, <span class="va">dixb</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">dix</span><span class="op">}</span></span>
<span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">dix</span><span class="op">)</span><span class="op">&gt;</span><span class="fl">2.009575</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">sig</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">sig</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">n_sig10</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plyr/man/count.html">count</a></span><span class="op">(</span><span class="va">n_sig10</span><span class="op">&gt;</span><span class="fl">0</span><span class="op">)</span><span class="op">-&gt;</span> <span class="va">n_sig10</span></span>
<span><span class="va">n_sig10</span></span></code></pre></div>
<pre><code>##       x freq
## 1 FALSE  607
## 2  TRUE  394</code></pre>
<p>En effet, le taux d’erreur de 1e espèce pour 10 analyses est de <span class="math inline">\(39.4\)</span> pourcents.</p>
<p>En d’autres termes, le problème est que, si on multiplie le nombre de comparaisons, on augmente également le risque de première espèce. Ainsi, il est nécessaire de distinguer l’erreur par comparaison (EC) et l’erreur par famille (EF).
L’erreur par comparaison est le seuil auquel on travaille sur une comparaison (par exemple 5%).
L’erreur par famille représente le seuil d’erreur pour l’ensemble des comparaisons.
En réalité, il n’était pas nécessaire de faire ces simulations car il est très simple de prédire le taux d’erreur de première espèce qu’on va avoir en fonction du nombre d’analyses. Il suffit d’appliquer la formule suivante :
<span class="math display">\[EF = 1 - (IC)^n \]</span>
où EF représente l’erreur par famille, IC représente l’intervalle de confiance et n le nombre d’analyses.</p>
<div class="sourceCode" id="cb350"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span><span class="op">-</span> <span class="op">(</span><span class="fl">0.95</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span></code></pre></div>
<pre><code>## [1] 0.0975</code></pre>
<div class="sourceCode" id="cb352"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span><span class="op">-</span><span class="op">(</span><span class="fl">0.95</span><span class="op">)</span><span class="op">^</span><span class="fl">5</span></span></code></pre></div>
<pre><code>## [1] 0.2262191</code></pre>
<div class="sourceCode" id="cb354"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span><span class="op">-</span><span class="op">(</span><span class="fl">0.95</span><span class="op">)</span><span class="op">^</span><span class="fl">10</span></span></code></pre></div>
<pre><code>## [1] 0.4012631</code></pre>
<p>Comme attendu, ces valeurs sont proches des pourcentages d’erreurs qu’on a obtenu par simulation.
Au-delà de l’erreur par comparaison et de l’erreur par famille. Il existe un troisième type d’erreur, appelée erreur par expérience. Cette terminologie un peu désuète à l’heure actuelle doit attirer votre attention sur le fait que, si on compare deux groupes, par exemple, sur un très grand nombre de variables dépendantes différentes, le test qui sera utilisé sera probablement un test de Student qui sera répété sur chacune des variables. Etant donné qu’il s’agit d’analyses différentes, on pourrait penser que le seuil de significativité est maintenu constant. En fait, il n’en est rien. Le taux d’erreurs par expérience inclut toutes les analyses conduites au sein d’une expérience.</p>
<p>En pratique, aucune correction particulière n’est appliquée entre des analyses différentes, excepté quelquefois lorsqu’une même analyse est répétée un grand nombre de fois (des t de Student successifs par exemple). Néanmoins, il vous est grandement recommandé de réaliser le moins de comparaisons possibles.</p>
<p>Lorsque vous ne pouvez pas éviter d’avoir un grand nombre de variables dépendantes, et donc de comparaisons, il est souhaitable de se tourner vers les analyses multivariées : MANOVA, extraction de facteurs par l’analyse factorielle exploratoire, ou analyse en composante principale pour réaliser une réduction de données.</p>
<p>Une autre manière pour éviter ce problème consiste à corriger la probabilité. Il existe une multitude de corrections des probabilité, dont la plus connue est sans aucun doute la correction de Bonferroni. Cette correction consiste à multiplier les probabilités obtenues pour chaque analyse par le nombre d’analyses réalisées. Les probabilités qui restent inférieures au seuil de significativité sont considérées comme significatives alors que celles qui sont supérieures au seuil de significativité après la correction doivent être considérées comme non significatives car pouvant être dues à une erreur de 1e espèce.</p>
<p>Imaginons le vecteur de probabilités organisées par ordre croissant ps :</p>
<div class="sourceCode" id="cb356"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ps</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.001</span>,<span class="fl">0.002</span>,<span class="fl">0.009</span>,<span class="fl">0.01</span>,<span class="fl">0.03</span>,<span class="fl">0.08</span><span class="op">)</span></span></code></pre></div>
<p>Sur ces 6 probabilités, les 5 premières doivent être considées comme révélant la présence d’un effet significatif. Cependant, 3 de ces probabilités deviennent non significatives après la correction de Bonferroni.</p>
<div class="sourceCode" id="cb357"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ps</span><span class="op">*</span><span class="fl">6</span></span></code></pre></div>
<pre><code>## [1] 0.006 0.012 0.054 0.060 0.180 0.480</code></pre>
<p>Cela signifie que, pour 3 analyses, il était tout à fait possible que l’effet était dû à une erreur de première espèce. Evidemment, il n’est pas nécessaire de réaliser cette correction à la main mais peut-être obtenu à l’aide d’une fonction R, qui est <code>p.adjust</code></p>
<div class="sourceCode" id="cb359"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/p.adjust.html">p.adjust</a></span><span class="op">(</span><span class="va">ps</span>, <span class="st">"bonferroni"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.006 0.012 0.054 0.060 0.180 0.480</code></pre>
<p>Si la correction de Bonferroni permet de maintenir l’erreur de 1e espèce constante, cette correction augmente le risque de seconde espèce. Pour éviter ce problème, il est préférable d’utiliser la correction de Holm. Le principe de cette correction est le même que celui utilisé pour la correction de Bonferroni, mais en prenant en compte le nombre d’analyse qu’il reste encore à corriger. Pour le formuler autrement, on multiplie chaque probabilité par son rang en ordre décroissant.</p>
<div class="sourceCode" id="cb361"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">rangs</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/rank.html">rank</a></span><span class="op">(</span><span class="op">-</span><span class="va">ps</span><span class="op">)</span></span>
<span><span class="va">rangs</span></span></code></pre></div>
<pre><code>## [1] 6 5 4 3 2 1</code></pre>
<div class="sourceCode" id="cb363"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ps</span><span class="op">*</span><span class="va">rangs</span></span></code></pre></div>
<pre><code>## [1] 0.006 0.010 0.036 0.030 0.060 0.080</code></pre>
<p>Notez que, contrairement à Bonferroni, seule une probabilité est considérée comme non significative après correction alors qu’elle était significative avant la correction.</p>
<p>A nouveau, il est possible d’utiliser la fonction <code>p.adjuste</code> pour obtenir cette correction automatiquement :</p>
<div class="sourceCode" id="cb365"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/p.adjust.html">p.adjust</a></span><span class="op">(</span><span class="va">ps</span>, <span class="st">"holm"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.006 0.010 0.036 0.036 0.060 0.080</code></pre>
<p>Peut-être avez-vous remarquer que, dans la correction de la probabilité à la main, la 4e probabilité corrigée manuellement vaut 0.03, alors qu’elle vaut 0.036 quand elle est corrigée avec <code>p.adjust</code>. Ce phénomène s’explique aisément par le fait que la 4e probabilité non corrigée vaut 0.01 alors que la 3e vaut 0.009. Comme il n’est pas normal qu’une probabilité corrigée ait une valeur supérieure à une autre probabilité qui lui était supérieure quand elles n’étaient pas corrigées, la règle est qu’une probabilité corrigée ne peut pas être inférieure à une autre probabilité si cette probabilité lui était inférieure avant la correction, raison pour laquelle la 3e et la 4e probabilité ont la même valeur, à savoir 0.036.</p>
<p>Pour ceux qui veulent développer leurs compétences de p-hacker et voir comment vous pouvez obtenir un effet significatif alors que vous n’auriez pas dû en avoir un, vous pouvez utiliser l’application shiny présente sur le lien suivant :
<a href="http://shinyapps.org/apps/p-hacker/" class="uri">http://shinyapps.org/apps/p-hacker/</a></p>
<p>Au finale, les situations minimales où il faudra utiliser ces corrections sont dans les matrices de corrélations et les comparaisons a posteriori dans les anova où les hypothèses.</p>
<p>En réalité, toutes les analyses d’une même recherche devraient avoir leur probabilité corrigée, mais cette pratique est peu courante.</p>
<p>Une dernière remarque concernant l’erreur par comparaison et l’erreur par famille.
Il existe un troisième type d’erreur, appelée erreur par expérience.
Cette terminologie un peu désuète à l’heure actuelle doit attirer votre attention sur le fait que, si on compare deux groupes par exemple, sur un très grand nombre de variables dépendantes différentes, le test qui sera utilisé sera probablement un test de Student qui sera répété sur chacune des variables. Etant donné qu’il s’agit d’analyses différentes, on pourrait penser que le seuil de significativité est maintenu constant.
En fait, il n’en est rien. Le taux d’erreurs par famille inclut toutes les analyses conduites au sein d’une expérience.
En pratique, aucune correction particulière n’est appliquée entre des analyses différentes, excepté quelquefois lorsqu’une même analyse est répétée un grand nombre de fois (des t de Student successifs par exemple). Néanmoins, il vous est grandement recommandé de réaliser le moins de comparaisons possibles.
Lorsque vous ne pouvez pas éviter d’avoir un grand nombre de variables dépendantes, et donc de comparaisons, il est souhaitable de se tourner vers les analyses multivariées : MANOVA, extraction de facteurs par l’analyse factorielle exploratoire, ou analyse en composante principale pour réaliser une réduction de données.</p>
</div>
</div>
<div id="dautres-manières-de-penser-les-statistiques" class="section level3" number="9.5.2">
<h3>
<span class="header-section-number">9.5.2</span> D’autres manières de penser les statistiques<a class="anchor" aria-label="anchor" href="#dautres-mani%C3%A8res-de-penser-les-statistiques"><i class="fas fa-link"></i></a>
</h3>
<div id="la-taille-deffet" class="section level4" number="9.5.2.1">
<h4>
<span class="header-section-number">9.5.2.1</span> La taille d’effet<a class="anchor" aria-label="anchor" href="#la-taille-deffet"><i class="fas fa-link"></i></a>
</h4>
<p>Que ce soit en utilisant la valeur de la probabilité ou l’intervalle de confiance, on peut adresser comme critique que, aussi infime que soit la différence, avec un échantillon suffisamment grand, un effet significatif sera observé.</p>
<p>Pour illustrer ce phénomène, regarder les deux photos ci-dessous et décider celle que vous préférez. Celle de gauche représente les lacs de Plivitce en Croatie et à droite, le coucher du soleil sur le Grand Canyon.</p>
<div class="inline-figure"><img src="inference/Canyon.png" width="300px"></div>
<p>On peut imaginer que la préférence pour le payasage dépend de la filière à laquelle vous appartenez. Ainsi, on pourrait imaginer comparer des étudiants en psychologie avec des étudiants en statistiques. Les données sont présentées dans la table 4.</p>
<div class="sourceCode" id="cb367"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/djnavarro/lsr">lsr</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"europe"</span>, <span class="st">"europe"</span>, <span class="st">"usa"</span>, <span class="st">"usa"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"psycho"</span>,<span class="st">"stat"</span>, <span class="st">"psycho"</span>, <span class="st">"stat"</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">16</span>,<span class="fl">14</span>,<span class="fl">14</span>,<span class="fl">16</span><span class="op">)</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">data1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">data1</span><span class="op">)</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lieu"</span>, <span class="st">"etudiants"</span>, <span class="st">"effectifs"</span><span class="op">)</span></span>
<span><span class="va">tab</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/tapply.html">tapply</a></span><span class="op">(</span><span class="va">data1</span><span class="op">$</span><span class="va">effectifs</span>,<span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">data1</span><span class="op">$</span><span class="va">lieu</span>,<span class="va">data1</span><span class="op">$</span><span class="va">etudiants</span><span class="op">)</span>,<span class="va">sum</span>,na.rm<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> </span>
<span><span class="fu">kable</span><span class="op">(</span><span class="va">tab</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left"></th>
<th align="right">psycho</th>
<th align="right">stat</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">europe</td>
<td align="right">16</td>
<td align="right">14</td>
</tr>
<tr class="even">
<td align="left">usa</td>
<td align="right">14</td>
<td align="right">16</td>
</tr>
</tbody>
</table></div>
<p><small>Table 4. Table des effectifs concernant la préférence pour les images en fonction de la filière </small></p>
<p>Pour tester s’il existe une dépendance entre la préférence et le type d’études, on va réaliser un <span class="math inline">\(\chi^2\)</span> d’indépendance.</p>
<div class="sourceCode" id="cb368"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">tab</span>, correct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  tab
## X-squared = 0.26667, df = 1, p-value = 0.6056</code></pre>
<p>Cette analyse révèle qu’il n’y a pas de lien entre la préférence et le type d’étude, <span class="math inline">\(\chi^2\)</span>(1) = 0.267, p= .6056.</p>
<p>Néanmoins, l’échantillon sur lequel l’analyse a été faite est relativement faible. Si cet échantillon était 100 fois plus grand, voici ce que nous obtiendrions.</p>
<div class="sourceCode" id="cb370"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tab</span><span class="op">*</span><span class="fl">100</span><span class="op">-&gt;</span><span class="va">tab2</span></span>
<span><span class="va">tab2</span></span></code></pre></div>
<pre><code>##        psycho stat
## europe   1600 1400
## usa      1400 1600</code></pre>
<div class="sourceCode" id="cb372"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">tab2</span>, correct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Pearson's Chi-squared test
## 
## data:  tab2
## X-squared = 26.667, df = 1, p-value = 2.418e-07</code></pre>
<p>Donc, contraitement à la première analyse, cette analyse indique qu’il existe un lien entre la formation et la préférence pour la photo. Cela indique que, pour des jeux de données de taille différente, la valeur de la statistique n’est pas informative.</p>
<p>Pour rendre les choses comparable, il faut calculer une taille d’effet. Il existe deux familles de tailles d’effet : la famille de d et la famille des <span class="math inline">\(R^2\)</span>. La famille des d consiste à présenter la taille d’effet comme un “distance” alors que dans la famille des <span class="math inline">\(R^2\)</span>, on présente la taille d’effet comme un pourcentage de variance expliquée.</p>
<p>Pour le <span class="math inline">\(\chi^2\)</span> d’indépendance, une des mesures de la taille d’effet est le V de Cramer (qu’on pourrait élever au carré pour avoir un pseudo-pourcentage de variance expliquée). On obtient ce V de Cramer grâce à la fonction <code>cramersV</code> du package ‘lsr’.</p>
<div class="sourceCode" id="cb374"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lsr/man/cramersV.html">cramersV</a></span><span class="op">(</span><span class="va">tab</span>, correct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.06666667</code></pre>
<div class="sourceCode" id="cb376"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lsr/man/cramersV.html">cramersV</a></span><span class="op">(</span><span class="va">tab2</span>, correct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## [1] 0.06666667</code></pre>
<p>On constate que, peu importe la taille d’échantillon, la valeur est identique : le V de Cramer vaut 0.067. Ainsi, la taille d’effet rend les études comparables entre elles.</p>
<p>Pour comprendre en quoi la taille d’effet peut être considéré comme un pourcentage de variance expliqué. Intéressons-nous à la corrélation.</p>
<p>Une étude (réelle) a montré que le nombre d’arrestations pour consommation de marijuana aux USA était significativement corrélé au nombre de colonies d’abeilles productrices de miel (les données peuvent être trouvées ici : <a href="http://tylervigen.com/view_correlation?id=1582" class="uri">http://tylervigen.com/view_correlation?id=1582</a>)</p>
<p>La corrélation entre les deux variable vaut -0.911:</p>
<div class="sourceCode" id="cb378"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="va"><a href="https://personality-project.org/r/psych/">psych</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/psych/man/corr.test.html">corr.test</a></span><span class="op">(</span><span class="va">miel</span><span class="op">$</span><span class="va">Miel</span>, <span class="va">miel</span><span class="op">$</span><span class="va">Marijuana</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Call:corr.test(x = miel$Miel, y = miel$Marijuana)
## Correlation matrix 
## [1] -0.91
## Sample Size 
## [1] 200
## These are the unadjusted probability values.
##   The probability values  adjusted for multiple tests are in the p.adj object. 
## [1] 0
## 
##  To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
<p>Cela signifie que le pourcentage de variance expliquée est la valeur de cette corrélation au carré.</p>
<div class="sourceCode" id="cb380"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/psych/man/corr.test.html">corr.test</a></span><span class="op">(</span><span class="va">miel</span><span class="op">$</span><span class="va">Miel</span>, <span class="va">miel</span><span class="op">$</span><span class="va">Marijuana</span><span class="op">)</span><span class="op">$</span><span class="va">r</span><span class="op">^</span><span class="fl">2</span>,<span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.8295</code></pre>
<p>Donc, 83% de la variance est expliquée par le lien entre le nombre de colonies d’abeilles et le nombre d’arrestation pour possession de marijuana (vous savez à présent ce qu’il vous reste à faire si vous consommez de la marijuana).</p>
<p>Pour comprendre qu’il s’agit d’un pourcentage de variance, il faut réaliser le modèle linéaire correspondant à cette corrélation (en l’occurrence, le sens a peu d’importance, l’objectif n’est pas de déterminer la variable qui prédit l’autre).</p>
<div class="sourceCode" id="cb382"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">modele</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">miel</span><span class="op">$</span><span class="va">Miel</span><span class="op">~</span><span class="va">miel</span><span class="op">$</span><span class="va">Marijuana</span><span class="op">)</span></span></code></pre></div>
<p>A partir de ce modèle, on peut voir que la variance de la variable ‘Miel’ est la somme entre la variance des valeurs prédites par le modèle (obtenues par la fonction &lt;code&lt;fitted) et la variance des résidus (obtenus par la fonction <code>residuals</code>).</p>
<div class="sourceCode" id="cb383"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">miel</span><span class="op">$</span><span class="va">Miel</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 75406.48</code></pre>
<div class="sourceCode" id="cb385"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">modele</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">modele</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 75406.48</code></pre>
<p>On peut donc déterminer quel est le pourcentage de la variance de la variable ‘Miel’ qui est prédit par la variance expliquée par le modèle :</p>
<div class="sourceCode" id="cb387"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">modele</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">miel</span><span class="op">$</span><span class="va">Miel</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.8294704</code></pre>
<p>Cette valeur correspond à la valeur de la corrélation au carré.</p>
<p>Le fait que la taille d’effet soit comparable entre les études fait que plusieurs revues et sociétés savantes (telle que l’American Psychological Association ) incitent à fournir les tailles d’effet. Certains auteurs recommandent même d’abandonner le report de la valeur de la probabilité (qui a finalement peu d’intérêt et dépend de la taille de l’échantillon) pour focaliser sur une analyse plus minitieuse de la taille d’effet.</p>
<p>Une illustration intéressante de l’importance de la compréhension de la taille d’effet provient de l’analyse de l’effet de la mémantine, un traitement contre les démences de type Alzheimer. Cette question est fortement politisée à l’heure actuelle car le gouvement a décidé de ne plus rembourser les frais liés à ces médicaments. Des associations, comme l’association France Alzheimer, s’insurge en arguant que ces médicaments ont un effet, bien qu’il soit modéré.
Sans vouloir entrer dans un cours complet sur la mémantine, une méta-analyse plutôt récente a été réalisée pour tester l’efficacité de la mémantine sur la sphère comportementale (Kishi &amp; Iwata, 2017). Les auteurs concluent que le médicament est efficace sur la plupart des aspects de la sphère comportementale. Cependant, ces auteurs ne semblent pas comprendre leur taille d’effet. En effet, la taille d’effet est aux alentours de 0.1 (il s’agit d’un d de Cohen). Présenté ainsi, il est difficile de se faire une opinion sur l’efficacité du médicament.
Bien sûr l’effet est significatif puisque, agrégées, les études de la méta-analyse porte sur plusieurs milliers de patients. La question qu’il faut se poser est quel est le vrai impact de la mémantine sur les aspects comportementaux des patients. En moyenne, une personne atteinte de la maladie d’Alzheimer va vivre avec sa maladie 10 ans. La mémantine coûte environ 36 euros pour 28 pillule à raison d’une pillule par jour. Le coût pour le patient est donc de 4741 euros au bout de 10 ans.</p>
<p>Si vous décidiez de soudoyer un enseignant et qu’il vous demandait 4741 euros pour augmenter votre moyenne de 0.25 points (données réelles sur les notes des étudiants de psychologie), est-ce que vous estimeriez que c’est un bon investissement ? Pourtant, voilà à quoi correspond l’effet de la mémantine et voilà pourquoi il est indispensable de comprendre la notion de taille d’effet.</p>
</div>
<div id="lintervalle-de-confiance" class="section level4" number="9.5.2.2">
<h4>
<span class="header-section-number">9.5.2.2</span> L’intervalle de confiance<a class="anchor" aria-label="anchor" href="#lintervalle-de-confiance"><i class="fas fa-link"></i></a>
</h4>
<p>Normalement, il est acquis à présent que, lorsque vous faites une analyse statistique, le test que vous réalisez teste l’absence de différence et que, si la probabilité renvoyée est inférieure au seuil de significativité alors vous considérez que la différence est significative. On peut appliquer le principe de manière similaire avec l’intervalle de confiance.</p>
<p>Généralement, un intervalle de confiance est à 95% (le complément de l’erreur de <span class="math inline">\(1^e\)</span> espèce). Il s’agit des limites entre lesquelles le paramètre que vous estimez va se situer dans 95% des situations. La Figure 8 illustre l’intervalle de confiance pour l’estimation d’une moyenne. Cinquante échantillons ont été tirés aléatoirement dans une population et on estime la moyenne de chacun de ces échantillons ainsi que l’intervalle de confiance autour de la moyenne estimée pour chacun d’eux. On observe que 95% (96% pour être précis) des estimations l’intervalle de confiance autour de la moyenne estimée coupe l’axe verticale de la moyenne de la population. Ainsi, quand l’intervalle de confiance recouvre le paramètre, cela indique que la moyenne estimée ne se différencie pas significativement de la moyenne de la population.</p>
<div class="inline-figure"><img src="inference/CI2.png" width="300px"></div>
<p><small>Figure 8. Illustration de l’intervalle de confiance.</small></p>
<p>Vous pouvez reproduire ce type de graphique à l’aide du package ‘TeachingDemos’</p>
<div class="sourceCode" id="cb389"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st">"TeachingDemos"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/TeachingDemos/man/ci.examp.html">ci.examp</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>Il est possible de calculer un intervalle de confiance sur pratiquement tout. Lorsque l’intervalle de confiance porte sur une statistique, on considère qu’il n’y a pas de différence significative lorsque l’intervalle de confiance comprend la valeur de l’hypothèse nulle. Par exemple, pour un t de Student, l’hypothèse nulle est qu’il n’y a pas de différence entre deux moyennes, et si c’est le cas, la valeur du t vaudra 0.</p>
<p>Pour le comprendre, nous allons l’illustrer à l’aide d’une étude que nous avons réalisée et qui visait à déterminer pourquoi les super-héros gagnent toujours à la fin. Nous avons émis l’hypothèse que c’était tout simplement parce qu’ils étaient plus forts. A l’aide d’un matériel adapté complètement expérimental et top secret, nous avons donc mesuré la force de super-héros et de super-vilains. Les données sont présentées dans le Tableau 2</p>
<div class="datatables html-widget html-fill-item" id="htmlwidget-2d63fa7f17035b487e2d" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2d63fa7f17035b487e2d">{"x":{"filter":"none","vertical":false,"caption":"<caption>Tableau 2. Mesure de force chez les super-héros par rapport aux super-vilains<\/caption>","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32"],["superman","spiderman","Hulk","Captain_America","Flash","4_Fantastiques","Wolverine","Batman","Robin","iron_man","veuve_noir","wonder_woman","Thor","Judge_Dredd","Daredevil_","X_men","Joker","Onguoin","Lex_luthor","Metallo","Captain_cold","Bouffon_vert","Mauvais_mutants","Magnéto","Loki","Red_Hulk","Catwoman","Dark_Avengers","Baron_Zemo_","Captain_cold","Superboy_Prime","Docteur_Fatalis"],["super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_héros","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains","super_vilains"],[93,77,87,81,91,99,67,75,93,91,79,95,72,85,83,66,87,84,81,83,98,70,92,76,87,75,89,99,65,91,96,86]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Nom<\/th>\n      <th>Groupe<\/th>\n      <th>Force<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":3},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"Nom","targets":1},{"name":"Groupe","targets":2},{"name":"Force","targets":3}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script><p>Pour comparer la force de ces deux groupes, l’analyse la plus naturelle est de comparer la force moyenne des super-héros à celle des super-vilains. Le test adapté pour faire cette analyse est le t de Student pour échantillons indépendants</p>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Force by Groupe
## t = -0.44532, df = 29.959, p-value = 0.6593
## alternative hypothesis: true difference in means between group super_héros and group super_vilains is not equal to 0
## 95 percent confidence interval:
##  -8.728694  5.603694
## sample estimates:
##   mean in group super_héros mean in group super_vilains 
##                     83.3750                     84.9375</code></pre>
<p>Cette analyse fournit un intervalle de confiance indiquant que la “vraie” valeur du t de Student est située entre -8.72 et 5.60. Comme cet intervalle recouvre le zéro, on ne peut pas exclure que les deux groupes ne se différencient pas sur leur force.</p>
<p>Cette manière d’envisager les statistiques permet d’identifier rapidement une différence significative grâce aux représentations graphiques représentation graphique.</p>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-200-1.png" width="672"></div>
<p>Dans ce graphique, la ligne horizontale du milieu représente la moyenne, tandis que les limites supérieures et inférieures de la boîte représente la moyenne plus une erreur-type et la moyenne moins une erreur-type. Enfin, les extrémités des barres verticales représente l’intervalle de confiance à 95%.</p>
<p>Il existe deux manière de lire ce graphique : la première manière consiste à regarder la barre verticale. Si elle dépasse la barre horizontale représentant la moyenne de l’autre groupe, cela signifie que la différence n’est pas significative. Si elle ne l’atteint pas, c’est que la différence est significative. Comme l’intervalle de confiance à 95% est calculé en multipliant l’erreur-type par 1.96, on peut arriver à la même conclusion avec l’erreur-type comme information uniquement. En l’occurrence, comme les super-vilains ont une moyenne supérieure en force, on peut savoir si cette différence est significative en regardant la limite inférieure de la boîte (la ligne horizontale inférieure). Si cette ligne inférieure est au-dessus de la ligne supérieure de la boîte des super-héros, cela signifie qu’il y a au moins 2 erreurs-types qui séparent les deux groupes, et donc que la différence est significative. Dans notre exemple, la limite inférieure des super-vilains est à un niveau inférieur à la limite supérieure des super-héros. La différence est donc non significative.</p>
<p>Il est de plus en plus souvent demandé de fournir les intervalles de confiance dans les articles. Si certains chercheurs ne sont pas convaincus de leur utilité, pour Thompson (2002), l’intervalle de confiance est un moyen pour les tailles d’effets. Néanmoins, à partir de la probabilité, on peut retrouver sans difficulté l’intervalle de confiance (Altman, 2011).<br>
On peut raisonnablement penser que ces intervalles de confiance sont utiles dans les représentations graphiques, et que son utilité de fournir des informations sur l’intervalle à l’intérieur duquel se trouve le vrai paramètre dans 95% des situations (Jiroutek, &amp; Turner, 2016).</p>
<p><strong>note</strong> : il s’agit ici d’un abus de langage. En réalité, on devrait dire que, étant donné une moyenne d’une population, l’estimation de la moyenne d’un échantillon a 95% de chance d’être inclus dans l’intervalle de confiance. Ainsi, comme on ne peut avoir accès directement aux paramètres, on peut créé un intervalle autour de l’estimation du paramètre qui englobera le paramètre dans 95% des situations.</p>
</div>
<div id="les-bootstraps" class="section level4" number="9.5.2.3">
<h4>
<span class="header-section-number">9.5.2.3</span> Les bootstraps<a class="anchor" aria-label="anchor" href="#les-bootstraps"><i class="fas fa-link"></i></a>
</h4>
<p>Dans de nombreuses situations, l’hypothèse faite sur la distribution des données est que la distribution suit une distribution normale. Cependant, cette condition est loin d’être systématiquement respectée. Une manière de contourner ce problème pour estimer un paramètre de la manière la plus optimale possible est de réaliser un bootstrap.</p>
<p>Cette technique généraliste consiste à échantillonner dans un échantillon un grand nombre de fois. L’échantillon créé par bootstrap est de taille identique à la taille initiale de l’échantillon. Les échantillons sont néanmoins différents à chaque itération car l’échantillonnage est réalisé avec remise. Ainsi, l’échantillon est composé de Pierre, Paul, Jacques. Comme il y a remise, Pierre peut donc être tiré plusieurs fois et votre premier échantillon de bootstrap pourrait être Pierre, Pierre, Paul. Evidemment, pour que le bootstrap ait du sens, il faut que la taille de l’échantillon soit suffisamment importante pour que le même échantillon ne revienne pas dans la répétition de l’opération.</p>
<p>L’intérêt de réaliser un boostrap est qu’on se dégage de la distribution des données puisqu’on va créer notre intervalle de confiance par simulation. Donc, peu importe la distribution initiale des données, le bootstrap s’y adapatera puisque la simulation de la distribution se basera sur la forme spécifique de la distribution des données de notre échantillon.</p>
<p>Dans une de nos études, nous n’avons pas très bien compris l’expérience de Milgram sur la soumission à l’autorité. Dans l’étude originale de Milgram, les participants doivent soumettre des chocs électriques à un autre participant chaque fois qu’il commet une erreur à une question. Ces chocs deviennent de plus en plus immportant au fur et à mesure que le nombre d’erreurs augmente. A l’insu des participants, la personne qui reçoit les chocs est un comparse de l’expérimentateur qui joue la comédie car elle ne reçoit pas vraiment des chocs.</p>
<p>Dans notre étude, nous n’avions pas vraiment compris que c’était un comparse, alors nous avons administré à nos participants des chocs électriques pour qu’ils apprennent à jouer aux fléchettes (pour ceux/celles qui auraient le moindre doute sur la question, et qui voudraient me signaler aux comités d’éthique ou aux CPP, nous tenons à leur préciser que cette étude est un fake … notre laboratoire ne dispose pas de dispositif pour administrer des chocs électriques).
Nous avons voulu savoir si les personnes soumises à un choc électrique envoyaient leurs fléchettes plus près du centre de la cible. On sait que la distance habituelle du centre de la cible est de 34 mm dans notre cas. Nous avons donc réalisé cette étude auprès de 50 personnes. Voici les données :</p>
<pre><code>##  [1] 40 53 37 47 35 32 47 41 53 35 56 47 43 55 40 38 43 23 36 58 46 34 37 39 29
## [26] 45 46 29 54 42 38 36 50 50 32 37 40 44 41 59 33 55 47 51 46 31 43 51 11 39</code></pre>
<p>Pour déterminer si le groupe soumis à un choc électrique est plus proche du centre de la cible, il faut réaliser un t de Student comparaison à une norme.</p>
<div class="sourceCode" id="cb392"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">fleche</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 41.88</code></pre>
<div class="sourceCode" id="cb394"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">fleche</span><span class="op">)</span><span class="op">-</span><span class="fl">34</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">fleche</span><span class="op">)</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span><span class="op">-&gt;</span><span class="va">t.value</span> <span class="co"># le 34 mm est la norme connue dans la population</span></span>
<span><span class="va">t.value</span></span></code></pre></div>
<pre><code>## [1] 5.911544</code></pre>
<p>Dans le bootstrap, on va tirer au hasard avec remise un nombre d’observations de notre échantillon qui correspond à la taille de l’échantillon. Pour faire un tirage au sort, on utilise la fonction <code>sample</code>. On indique dans cette fonction la taille d’échantillon qu’on veut échantillonner et l’argument ‘replace’ permet de préciser si c’est un tirage avec remise ou non. L’argument ‘T’ (pour TRUE) indique que c’est avec remise.
Comme notre échantillon fait 50 personnes, il faut que chaque échantillon du boostrap soit composé de 50 personnes.</p>
<div class="sourceCode" id="cb396"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">fleche</span>,<span class="fl">50</span>,replace <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  [1] 43 43 36 32 38 32 33 47 43 38 23 35 29 58 55 50 47 37 53 37 35 34 43 29 47
## [26] 47 50 39 41 40 56 34 40 46 35 53 37 38 35 32 47 32 32 53 32 53 45 59 42 58</code></pre>
<p>Sur ce nouvel échantillon, on peut donc calculer un nouveau t de Student comparaison à une norme qui va avoir une valeur différente de l’échantillon initial.</p>
<div class="sourceCode" id="cb398"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">f2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">fleche</span>,<span class="fl">50</span>,replace <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span>
<span><span class="va">t2</span><span class="op">&lt;-</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">f2</span><span class="op">)</span><span class="op">-</span><span class="fl">34</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">f2</span><span class="op">)</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">t2</span></span></code></pre></div>
<pre><code>## [1] 8.344773</code></pre>
<p>Le principe du bootstrap est de répéter cette opération un grand nombre de fois (par exemple 1000, et au minimum 500) pour créer l’intervalle de confiance sur un paramètre ou une statistique. La boucle <code>for</code> permet de réaliser cette opération. On va créer un vecteur avec 1000 t de Student comparaison à une norme basé sur des échantillonnage avec remise. Notez qu’on peut également faire le bootstrap sur la moyenne pour connaître l’intervalle à l’intérieur duquel la vraie moyenne à 95% de chance d’être.</p>
<div class="sourceCode" id="cb400"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">999</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">f2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">fleche</span>,<span class="fl">50</span>,replace <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span>
<span>  <span class="va">t3</span><span class="op">&lt;-</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">f2</span><span class="op">)</span><span class="op">-</span><span class="fl">34</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">f2</span><span class="op">)</span><span class="op">/</span><span class="fl">50</span><span class="op">^</span><span class="fl">0.5</span><span class="op">)</span></span>
<span>  <span class="va">t2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">t2</span>, <span class="va">t3</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>A présent, l’objet t2 dans la mémoire de R est composé de 1000 valeurs, qui correspondent chacune à un t de Student comparaison à une norme qu’on a obtenues par échantillonnage avec remise.
Nous pouvons obtenir l’intervalle de confiance sur ces t de Student. Il existe plusieurs méthodes pour obtenir cet intervalle de confiance. L’une d’entre elle consiste à utiliser les percentiles. Comme nous voulons les 95% pourcents des t au centre de la courbe, on répartit les 5 pourcents de manière équitable sur les deux extrémités, c’est-à-dire 2.5% de chaque côté. On obtient ces centiles grâces à la fonction <code>quantile</code> en précisant les valeurs des centiles désirées, donc 0.025 et 0.975 dans notre cas.</p>
<div class="sourceCode" id="cb401"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">t2</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>,<span class="fl">0.975</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 3.565388 9.138221</code></pre>
<p>En l’occurrence, l’intervalle de confiance ne recouvre pas le 0, ce qui signifie qu’il est improbable que la valeur du t soit égale à 0. On peut donc interpréter cet intervalle comme révélant la présence d’un effet significatif.</p>
<p>Dans notre exemple, nous avons réaliser le boostrap sur la valeur de la statistique, mais on aurait pu le faire sur la moyenne. Dans ce cas, si l’intervalle ne recouvrait pas 34 (la norme), c’est-à-dire que 34 n’était pas compris entre la limite inférieure et la limite supérieure de l’intervalle de confiance, alors c’est qu’il y avait une différence significative. Dans le cas contraire, la différence était non significative.</p>
<p>Comme d’habitude, il n’est pas nécessaire de programmer soi-même le bootrap. Il existe un ensemble de packages dans R qui le font à votre place et, pour certains packages ont développé des fonctions spécifiques de bootstrap, qui sont prêt à l’emploi.</p>
<p>En l’occurrence, la fonction <code>boot</code> du package ‘boot’ permet de très bien faire cela. Nous allons en l’occurrence faire un boostrap sur une moyenne.</p>
<div class="sourceCode" id="cb403"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">boot</span><span class="op">)</span></span>
<span><span class="co"># on commence par créer une fonction où il faut des données et les itérations. </span></span>
<span><span class="va">meanfun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span>, <span class="va">i</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">d</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># on stocke une itération donnée dans l'objet d </span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span><span class="op">)</span> <span class="co"># on fait moyenne  </span></span>
<span><span class="op">}</span></span>
<span><span class="va">boot.out</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/boot/man/boot.html">boot</a></span><span class="op">(</span><span class="va">fleche</span>, statistic <span class="op">=</span> <span class="va">meanfun</span>, R<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/boot/man/boot.ci.html">boot.ci</a></span><span class="op">(</span><span class="va">boot.out</span><span class="op">)</span></span></code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boot.out)
## 
## Intervals : 
## Level      Normal              Basic         
## 95%   (39.26, 44.55 )   (39.18, 44.64 )  
## 
## Level     Percentile            BCa          
## 95%   (39.12, 44.58 )   (39.09, 44.56 )  
## Calculations and Intervals on Original Scale</code></pre>
<p>Notez que, comme les échantillons ne sont pas les mêmes d’une fois à l’autre, l’intervalle de confiance sera sensiblement modifié entre deux répétitions.</p>
<p>Pour terminer sur le bootstrap, comme précisé plus haut, il existe différentes manières de calculer l’intervalle de confiance. La méthode la plus robuste est le bootrap corrigé pour des biais d’asymétrie (BCa) (Efron &amp; Gong, 1983).</p>
</div>
</div>
</div>
<div id="lapproche-par-maximum-de-vraisemblance." class="section level2" number="9.6">
<h2>
<span class="header-section-number">9.6</span> L’approche par maximum de vraisemblance.<a class="anchor" aria-label="anchor" href="#lapproche-par-maximum-de-vraisemblance."><i class="fas fa-link"></i></a>
</h2>
<p>Le maximum de vraisemblance est un concept essentiel au niveau statistique car il amène la personne qui veut réaliser des statistiques à penser en termes de modèle. Il s’agit habituellement d’un estimateur qui est utilisé dans les techniques statistiques plus avancées telles que la régression logistique, les analyses factorielles ou les modèles linéaires mixtes, et plus généralement dans tous les modèles non linéaires. Néanmoins, on peut l’utiliser pour estimer n’importe quel paramètre.</p>
<p>En général, le maximum de vraisemblance est un méthode pour obtenir les estimations de paramètres inconnus en optimisant la fonction de vraisemblance.</p>
<p>Le principe la vraisemblance est d’estimer la probabilité d’observer les données de manière itérative. Ainsi, on part d’une valeur “aléatoire”, qui va être la solution initiale, et on va chercher à améliorer cette solution initiale de sorte à augmenter, c’est-à-dire optimiser, la probabilité d’observer cette distribution de données par simulation. Le maximum de vraisemblance est la valeur de la probabilité pour laquelle les paramètre seront optimisés pour avoir la probabilité maximale. Quand cette probabilité a atteint un maximum (moyennant une certaine tolérance), on dit que le modèle a convergé.</p>
<div id="explication-mathématique" class="section level3" number="9.6.1">
<h3>
<span class="header-section-number">9.6.1</span> Explication mathématique<a class="anchor" aria-label="anchor" href="#explication-math%C3%A9matique"><i class="fas fa-link"></i></a>
</h3>
<p><strong>AVERTISSEMENT</strong> : cette section peut être ignorée, en particulier pour ceux à qui les formules mathématiques donnent la nausée. Dans ce cas, vous pouvez vous reporter à la section suivante sur le ratio de vraisemblance. Pour les autres, que Dieu ait votre âme.</p>
<p>D’un point de vue mathématique, la vraisemblance est la densité de probabilité associée aux données observées :</p>
<p><span class="math display">\[L_x(\theta)= f(x)\]</span></p>
<p>Pour illustrer le concept, nous allons reprendre l’exemple des chocs électriques reçus par les participants quand ils s’éloignent du centre de la cible. On peut calculer la vraisemblance de la moyenne</p>
<p>Pour une variable numérique, la vraisemblance est maximale lorsque la moyenne et l’écart-type sont identiques à la moyenne et l’écart-type calculés.</p>
<div class="sourceCode" id="cb405"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">fleche</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 41.88</code></pre>
<div class="sourceCode" id="cb407"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">fleche</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 9.425627</code></pre>
<p>Dans cet exemple assez simpliste, nous voulons donc estimer la moyenne et l’écart-type. Fondamentale, on peut les calculer l’un après l’autre assez aisément. Cependant, dans des situations plus complexes, ce ne sera pas le cas. Nous allons donc essayer de deviner la moyenne et l’écart-type sur la base des données :</p>
<div class="sourceCode" id="cb409"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fleche</span></span></code></pre></div>
<pre><code>##  [1] 40 53 37 47 35 32 47 41 53 35 56 47 43 55 40 38 43 23 36 58 46 34 37 39 29
## [26] 45 46 29 54 42 38 36 50 50 32 37 40 44 41 59 33 55 47 51 46 31 43 51 11 39</code></pre>
<p>Les données sont comprises grosso modo entre 20 et 68. Il est raisonnable de considérer que la vraie moyenne se situe quelque part entre ces deux valeurs et que l’écart-type vaut environ <span class="math inline">\(1/4\)</span> de cette distance puisque 95% des observations sont comprises entre -1.96 et +1.96 écart-types. Ainsi, je devine que la moyenne est à 44 et l’écart-type vaut 12.</p>
<p>Je peux calculer la vraisemblance de cette estimation en calculant la densité de probabilité associée aux données (en considérant que les données suivent une distribution normale)</p>
<p>Ainsi, pour chaque observation d’une variable numérique, on peut estimer la densité de probabilité de cette observation sur la base d’une distribution normale (pour simplifier un peu, la hauteur de la courbe normale).</p>
<div class="sourceCode" id="cb411"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">44</span> , sd<span class="op">=</span> <span class="fl">12</span>, log<span class="op">=</span><span class="cn">F</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span> <span class="co"># on obtient la densité de probabilité pour chaque observation </span></span></code></pre></div>
<pre><code>##  [1] 0.03144860 0.02509479 0.02804390 0.03222234 0.02509479 0.02016423
##  [7] 0.03222234 0.03222234 0.02509479 0.02509479</code></pre>
<p>La fonction de vraisemblance est obtenue en appliquant le logarithme à chacune des observations.</p>
<div class="sourceCode" id="cb413"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">44</span> , sd<span class="op">=</span> <span class="fl">12</span>, log<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span> <span class="co"># on obtient la fonction de vraisemblance pour chaque observation </span></span></code></pre></div>
<pre><code>##  [1] -3.459401 -3.685095 -3.573984 -3.435095 -3.685095 -3.903845 -3.435095
##  [8] -3.435095 -3.685095 -3.685095</code></pre>
<p>On obtient la vraisemblance en additionnant le logarithme des probabilités d’observer cette distribution.</p>
<div class="sourceCode" id="cb415"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">44</span> , sd<span class="op">=</span> <span class="fl">12</span>, log<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## [1] -186.0881</code></pre>
<p>La valeur de la vraisemblance est ici particulièrement faible. Nous allons tenter de l’améliorer. Pour cela, je vais modifier les paramètres et déterminer si on peut augmenter la vraisemblance. Par exemple, je peux tester si la moyenne n’est pas à 43 plutôt qu’à 44.</p>
<div class="sourceCode" id="cb417"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">43</span> , sd<span class="op">=</span> <span class="fl">12</span>, log<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## [1] -185.5256</code></pre>
<p>La vraisemblance à augmenter. Je vais donc continuer et tenter de voir si la moyenne n’est pas à 42 au lieu de 43.</p>
<div class="sourceCode" id="cb419"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">42</span> , sd<span class="op">=</span> <span class="fl">12</span>, log<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## [1] -185.3103</code></pre>
<p>La vraisemblance continue à augmenter. On va donc continuer à estimer nos deux paramètres de manière itérative jusqu’à atteindre un maximum. Ce maximum sera atteint quand la moyenne testé sur la moyenne de nos données et l’écart-type sera l’écart-type des données :</p>
<div class="sourceCode" id="cb421"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">39.72</span> , sd<span class="op">=</span> <span class="fl">10.876</span>, log<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## [1] -184.6622</code></pre>
<p>On peut évidemment obtenir directement ces valeurs. Le package ‘EstimationTools’ permet de manipuler les différents paramères avec la fonction <code>maxlog</code>.</p>
<div class="sourceCode" id="cb423"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://jaimemosg.github.io/EstimationTools/">"EstimationTools"</a></span><span class="op">)</span></span></code></pre></div>
<pre><code>## Le chargement a nécessité le package : survival</code></pre>
<pre><code>## 
## Attachement du package : 'survival'</code></pre>
<pre><code>## L'objet suivant est masqué depuis 'package:boot':
## 
##     aml</code></pre>
<pre><code>## 
## &gt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;   EstimationTools Version 4.3.1   &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&lt;
##   Feel free to report bugs in https://github.com/Jaimemosg/EstimationTools/issues</code></pre>
<div class="sourceCode" id="cb428"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://jaimemosg.github.io/EstimationTools/reference/maxlogL.html">maxlogL</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">fleche</span>, dist <span class="op">=</span> <span class="st">'dnorm'</span>, start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span>,lower<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">20</span>, <span class="fl">5</span><span class="op">)</span>, upper<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">65</span>, <span class="fl">20</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">fit1</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">par</span></span></code></pre></div>
<pre><code>##      mean        sd 
## 41.880000  9.330895</code></pre>
<div class="sourceCode" id="cb430"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">objective</span></span></code></pre></div>
<pre><code>## [1] -182.6135</code></pre>
<p>Remarquez qu’il y a une toute petite différence. Cela est dû au fait que l’estimation de l’écart-type est légèrement différente de celle calculée.</p>
<p>Dans ce modèle, la vraisemblance est égale à -188.7698. Cette valeur n’est pas directement utilisable. Il est nécessaire de calculer la déviance en la multipliant par -2.</p>
<div class="sourceCode" id="cb432"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="op">-</span><span class="fl">188.9068</span> <span class="co"># calcul de la déviance</span></span></code></pre></div>
<pre><code>## [1] 377.8136</code></pre>
</div>
<div id="le-ratio-de-vraisemblance-lrt" class="section level3" number="9.6.2">
<h3>
<span class="header-section-number">9.6.2</span> Le ratio de vraisemblance (LRT)<a class="anchor" aria-label="anchor" href="#le-ratio-de-vraisemblance-lrt"><i class="fas fa-link"></i></a>
</h3>
<p>Le ratio de vraisemblance (LRT) est la différence entre deux déviances. Cette différence se distribue approximativement comme un <span class="math inline">\(\chi^2\)</span> ayant comme degrés de liberté le nombre de paramètres estimés.</p>
<p><span class="math display">\[LRT = -2 [l(\theta-l(\hat\theta))]\]</span></p>
<div class="sourceCode" id="cb434"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">LRT</span><span class="op">&lt;-</span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">44</span> , sd<span class="op">=</span> <span class="fl">12</span>, log<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">fleche</span>, mean<span class="op">=</span> <span class="fl">39.72</span> , sd<span class="op">=</span> <span class="fl">10.876</span>, log<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span> <span class="op">)</span><span class="op">)</span></span>
<span><span class="va">LRT</span></span></code></pre></div>
<pre><code>## [1] 2.851758</code></pre>
<p>Ainsi, il faut se demander un <span class="math inline">\(\chi^2\)</span> de 2.851758 ayant 2 degrés de liberté est significatif.</p>
<div class="sourceCode" id="cb436"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">LRT</span>, df<span class="op">=</span><span class="fl">2</span>, lower<span class="op">=</span><span class="cn">F</span><span class="op">)</span> <span class="co"># calcule la probabilité de la valeur LRT avec 2 degrés de liberté, en donnant la probabilité d'avoir une valeur supérieure à cette valeur (lower = F)  </span></span></code></pre></div>
<pre><code>## [1] 0.2402972</code></pre>
</div>
<div id="les-critères-dinformation." class="section level3" number="9.6.3">
<h3>
<span class="header-section-number">9.6.3</span> Les critères d’information.<a class="anchor" aria-label="anchor" href="#les-crit%C3%A8res-dinformation."><i class="fas fa-link"></i></a>
</h3>
<p>Les critères d’information fournissent une manière d’évaluer l’ajustement d’un modèle sur la base de la valeur optimale du log de vraisemblance tout en pénalisant les modèles qui ne sont pas parcimonieux.</p>
<p>L’intérêt des critères d’information est qu’ils permettent de comparer n’importe quels modèles ajustés sur le même jeu de données. Il n’est donc pas nécessaire que les modèles soient emboîtés.</p>
<p>Il existe deux critères d’information qui sont particulièrement utilisés : le AIC (Critère d’Informations d’Akaike) et le BIC (Critère d’Information de Bayes).</p>
<p>Dans les deux cas, la logique est la même : on va s’appuyer sur le calcul de la vraisemblance, mais en pénalisant le modèle à chaque paramètre estimé.</p>
<p>Pour le AIC, la déviance va être pénalisée en additionnant 2 fois le nombre de prédicteur.</p>
<p><span class="math display">\[ AIC=-2×l(β ̂,θ ̂ )+2p \]</span></p>
<p>Dans notre modèle, le log de vraisemblance vaut 2.851758, la déviance vaut donc -2$$2.851758, ce qui donne -5.703516. Les degrés de liberté résiduels sont de 2. Le AIC vaut donc :</p>
<div class="sourceCode" id="cb438"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="va">fit1</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">objective</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="fl">2</span> <span class="co"># ou le second 2 représente le nombre de paramètres estimés </span></span></code></pre></div>
<pre><code>## [1] 369.2269</code></pre>
<p>qu’on obtient directement avec la fonction AIC :</p>
<div class="sourceCode" id="cb440"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">fleche</span><span class="op">~</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="co"># on réalise un modèle linéaire où on ne calcule que la constante, ce qui permet d'estimer la moyenne et la variance (ou l'écart-type)</span></span></code></pre></div>
<pre><code>## [1] 369.2269</code></pre>
<p>Pour le critère d’information de Bayes, le principe est assez similaire, la différence porte sur la manière de calculer la pénalité pour le manque de parcimonie. Ainsi, le nombre de paramètres estimés sera multiplié par le logarithme de la taille de l’échantillon.</p>
<p><span class="math display">\[BIC=-2×l(β ̂,θ ̂ )+p×ln(n) \]</span></p>
<div class="sourceCode" id="cb442"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="va">fit1</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">objective</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">50</span>, base<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 373.051</code></pre>
<p>qu’on obtient directement avec la fonction BIC :</p>
<div class="sourceCode" id="cb444"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">BIC</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">fleche</span><span class="op">~</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="co"># on réalise un modèle linéaire où on ne calcule que la constante, ce qui permet d'estimer la moyenne et la variance (ou l'écart-type)</span></span></code></pre></div>
<pre><code>## [1] 373.051</code></pre>
<p>Puisque ces deux critères d’informations s’appuient sur la déviance pour le calcul, à laquelle on va ajouter une pénalité aux modèles pour lesquels de nombreux paramètres sont estimés, cela signifie que, comme pour la déviance où, plus la valeur est faible, plus les données sont ajustées, plus la valeur pour ces deux critères d’informations est petite, meilleur est l’ajustement.</p>
</div>
</div>
<div id="lapproche-bayesienne" class="section level2" number="9.7">
<h2>
<span class="header-section-number">9.7</span> L’approche bayesienne<a class="anchor" aria-label="anchor" href="#lapproche-bayesienne"><i class="fas fa-link"></i></a>
</h2>
<p>Comme nous l’avons évoqué, pour publier, il faut des résultats, résultats dits positifs. La raison de ce phénomène est que lorsqu’on tolère l’hypothèse nulle, nous n’avons pas d’information sur le fait qu’on n’a pas assez d’information pour avoir un résultat significatif ou s’il n’y a vraiment pas d’effet.</p>
<p>Pour le formuler autrement l’absence de preuve n’est pas la preuve de l’absence. Cette difficulté est une des grosses limites des tests d’hypothèse nulle.</p>
<p>Une autre critique fréquemment adressée aux tests d’hypothèse nulle est que le seuil à 0.05 est arbitraire, c’est pourquoi un certain nombre de chercheurs encouragent l’utilisation des facteurs bayesiens.</p>
<div id="les-facteurs-bayesiens-un-rapport-entre-deux-vraisemblances" class="section level3" number="9.7.1">
<h3>
<span class="header-section-number">9.7.1</span> Les facteurs bayesiens : un rapport entre deux vraisemblances<a class="anchor" aria-label="anchor" href="#les-facteurs-bayesiens-un-rapport-entre-deux-vraisemblances"><i class="fas fa-link"></i></a>
</h3>
<p>Supposons un amphi pour lequel on se demande si la parité est respectée. Dans cet amphi, il y a 200 personnes, dont 160 femmes. La probabilité que la parité soit respectée s’obtient par une binomiale</p>
<p><span class="math display">\[ \begin{pmatrix} 200 \\160  \end{pmatrix} 0,5 ^{160} (1-0,5)^{40}\ \]</span></p>
<p>et vaut</p>
<div class="sourceCode" id="cb446"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p.h0</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">160</span>, <span class="fl">200</span>, <span class="fl">0.5</span>,<span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">p.h0</span></span></code></pre></div>
<pre><code>## [1] 1.275816e-18</code></pre>
<p>L’hypothèse alternative à cette hypothèse est que la parité n’est pas respectée.
La probabilité que la parité ne soit pas respectée (le ratio h/f est n’importe quelle autre valeur que 0,5) s’obtient par :</p>
<p><span class="math display">\[\int_{0}^{1} \begin{pmatrix} 200 \\160  \end{pmatrix} p ^{160} (1-p)^{40}\, \mathrm{d}p \]</span></p>
<p>** note : pour être parfaitement précis, il faudrait retirer de l’intégrale la probabilité d’avoir 0.5)</p>
<p>et vaut :</p>
<div class="sourceCode" id="cb448"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fdbinom</span><span class="op">&lt;-</span><span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">=</span><span class="cn">NULL</span><span class="op">)</span><span class="op">{</span></span>
<span>         <span class="va">r</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">160</span>, <span class="fl">200</span>, <span class="va">p</span>,<span class="cn">FALSE</span><span class="op">)</span></span>
<span>        <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span>
<span>        <span class="op">}</span></span>
<span></span>
<span><span class="va">p.h1</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="va">fdbinom</span>, <span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">p.h1</span><span class="op">$</span><span class="va">value</span></span></code></pre></div>
<pre><code>## [1] 0.004975124</code></pre>
<p>Selon les tests d’hypothèse nulle, on est amené à rejeter à la fois l’hypothèse de la parité et l’hypothèse selon laquelle la parité n’est pas respectée.</p>
<p>Le facteur bayesien peut résoudre ce problème. En effet, il s’agit du rapport entre ces deux probabilités.</p>
<pre><code>## 1.275816e-18 / 0.004975124 = 3.899561e+15</code></pre>
<p>Ainsi, on sait quel est l’hypothèse la plus probable.</p>
<p>Un facteur bayesien s’interprète de la manière indiquée dans le Tableau 4. Notez que ce tableau teste l’hypothèse nulle. Les critères doivent être inversés si on teste l’hypothèse alternative.</p>
<small>Tableau 4. Seuil pour interpréter les facteurs bayesiens (Wagenmakers et al., 2011)</small>
<div class="centered">
<div class="inline-figure"><img src="inference/evidencefor.png" width="300px"></div>
</div>
<p>Cette approche permet donc de résoudre le problème des tests d’hypothèse nulle consistant à pouvoir tester une absence de différence.</p>
<p>Pour le comprendre, prenons deux groupes de 1000 personnes ayant exactement la même moyenne (i.e., 0) et le même écart-type (i.e.,1).</p>
<div class="sourceCode" id="cb451"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">groupe1</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">groupe2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>Pour comparer ces deux groupes, on va classiquement réaliser un t de Student pour échantillons indépendants.</p>
<p>Nous allons à présent pouvoir comparer l’évolution de la décision lorsque la taille d’échantillon augmente par rapport tant lorsqu’on adopte un test d’hypothèse que lorsqu’on utilise les facteurs bayesiens.</p>
<div class="sourceCode" id="cb452"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://richarddmorey.github.io/BayesFactor/">BayesFactor</a></span><span class="op">)</span></span></code></pre></div>
<pre><code>## Le chargement a nécessité le package : coda</code></pre>
<pre><code>## Le chargement a nécessité le package : Matrix</code></pre>
<pre><code>## ************
## Welcome to BayesFactor 0.9.12-4.7. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).
## 
## Type BFManual() to open the manual.
## ************</code></pre>
<div class="sourceCode" id="cb456"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="va">list.t</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">list.bf</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">5</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">ttest</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">groupe1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">i</span><span class="op">]</span>, <span class="va">groupe2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">i</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">list.t</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">list.t</span>,  <span class="va">ttest</span><span class="op">$</span><span class="va">p.value</span><span class="op">)</span></span>
<span>  <span class="va">bf</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/BayesFactor/man/ttestBF.html">ttestBF</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">groupe1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">i</span><span class="op">]</span>, y <span class="op">=</span> <span class="va">groupe2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">i</span><span class="op">]</span>, rscale <span class="op">=</span> <span class="st">"medium"</span><span class="op">)</span></span>
<span>  <span class="va">list.bf</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">list.bf</span>, <span class="fu"><a href="https://rdrr.io/pkg/BayesFactor/man/extractBF-methods.html">extractBF</a></span><span class="op">(</span><span class="va">bf</span><span class="op">)</span><span class="op">$</span><span class="va">bf</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">simul</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>index<span class="op">=</span><span class="fl">5</span><span class="op">:</span><span class="fl">1000</span>, <span class="st">"Bayes.Factor"</span><span class="op">=</span><span class="va">list.bf</span>,<span class="st">"test.t.p"</span><span class="op">=</span><span class="va">list.t</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cutoff.bf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="cn">Inf</span>, <span class="cn">Inf</span><span class="op">)</span>, y <span class="op">=</span><span class="fl">0.33</span>, cutoff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">cutoff.bf2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="cn">Inf</span>, <span class="cn">Inf</span><span class="op">)</span>, y <span class="op">=</span><span class="fl">3</span>, cutoff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">p</span><span class="op">&lt;-</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">simul</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">index</span>, y<span class="op">=</span><span class="va">Bayes.Factor</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">3.5</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span> <span class="va">x</span>, <span class="va">y</span>, linetype <span class="op">=</span> <span class="va">cutoff</span> <span class="op">)</span>, <span class="va">cutoff.bf</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span> <span class="va">x</span>, <span class="va">y</span>, linetype <span class="op">=</span> <span class="va">cutoff</span> <span class="op">)</span>, <span class="va">cutoff.bf2</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Taille de l'échantillon"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Valeur du facteur bayesien"</span><span class="op">)</span><span class="op">+</span></span>
<span>   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"none"</span><span class="op">)</span><span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Figure 11. Evolution de la valeur du Facteur Bayesien pour un t de Student \n en fonction de la taille de l'échantillon."</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.line.x <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_line</a></span><span class="op">(</span>color<span class="op">=</span><span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span>,</span>
<span>                         axis.line.y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_line</a></span><span class="op">(</span>color<span class="op">=</span><span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>text <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>size<span class="op">=</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cutoff</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="cn">Inf</span>, <span class="cn">Inf</span><span class="op">)</span>, y <span class="op">=</span> <span class="fl">0.05</span>, cutoff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">p2</span><span class="op">&lt;-</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">simul</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">index</span>, y<span class="op">=</span><span class="va">test.t.p</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span> <span class="va">x</span>, <span class="va">y</span>, linetype <span class="op">=</span> <span class="va">cutoff</span> <span class="op">)</span>, <span class="va">cutoff</span><span class="op">)</span><span class="op">+</span></span>
<span>   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Taille de l'échantillon"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Valeur de la probabilité du test t"</span><span class="op">)</span><span class="op">+</span></span>
<span>   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"none"</span><span class="op">)</span><span class="op">+</span></span>
<span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Figure 10. Evolution de la probabilité pour un t de Student \n en fonction de la taille de l'échantillon."</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.line.x <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_line</a></span><span class="op">(</span>color<span class="op">=</span><span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span>,</span>
<span>                         axis.line.y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_line</a></span><span class="op">(</span>color<span class="op">=</span><span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>text <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>size<span class="op">=</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Commençons pour regarder l’évolution de la probabilité, qui est présentée en Figure 10. On se rend compte que peu importe la taille de l’échantillon, la probabilité associée au test de Student peut se situer entre n’importe quelle valeur sur une échelle allant de 0 à 1, avec un certain nombre de valeurs inférieures au seuil de significativité à 0.05, identifié par la droite horizontale. Ceci amène donc à la conclusion que peu importe la probabilité, nous ne sommes pas en mesure de tirer une conclusion.</p>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-229-1.png" width="672"></div>
<p>Si on s’intéresse à présent à l’évolution du Facteur Bayes (Figure 11). On constate que le FB ne dépasse jamais le seuil de 3 (ligne horizontale du haut) qui indique la présence d’une différence significative entre les deux groupes. En revanche, à partir d’un échantillon suffisamment élevé, le FB ne dépasse plus le seuil de 0.33 (la ligne horizontale du bas) qui indique des éléments en faveur de l’absence de différence. Il s’agit donc d’une grosse plus-value des facteurs bayesiens.</p>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-230-1.png" width="672"></div>
<p>Pour utiliser les facteurs bayesiens, on applique le même raisonnement que pour les tests d’hypothèse nulle : donc si vous devez un t de Student, vous ferez un t de Student avec une approche bayesienne aussi.</p>
<p>Le package R qui permet d’adopter cette approche est le package ‘BayesFactor’ (il en existe d’autres, mais ils sont un peu plus complexes d’utilisation).</p>
<p>Nous pouvons reprendre notre exemple sur la force des super-héros pour illustrer la manière dont la fonction doit être utilisée.</p>
<div class="sourceCode" id="cb457"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">bf</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/BayesFactor/man/ttestBF.html">ttestBF</a></span><span class="op">(</span>formula<span class="op">=</span><span class="va">Force</span><span class="op">~</span><span class="va">Groupe</span>, data<span class="op">=</span><span class="va">super</span>, rscale <span class="op">=</span> <span class="st">"medium"</span>, paired<span class="op">=</span><span class="cn">F</span><span class="op">)</span></span>
<span><span class="va">bf</span></span></code></pre></div>
<pre><code>## Bayes factor analysis
## --------------
## [1] Alt., r=0.707 : 0.3628706 ±0%
## 
## Against denominator:
##   Null, mu1-mu2 = 0 
## ---
## Bayes factor type: BFindepSample, JZS</code></pre>
<p>Vous avez peut-être identifié que, par rapport à la fonction du test de Student classique, il y a un argument supplémentaire, qui est le rscale.</p>
<p>Le r-scale correspond à la taille d’effet en valeur absolue que le chercheur estime pouvoir observer dans plus de 50% des situations. La valeur par défaut (“medium”) pour le test t est de 0.707.
En d’autres termes, dans les facteurs bayesiens, il faut explicitement préciser la taille d’effet. C’est ce qu’on appelle le prior. Pour les utilisateurs des tests d’hypothèse nulle, il est raisonnable d’utiliser comme prior la valeur du d de Cohen qu’on s’attend à observer (Lakens, 2018).</p>
<p>Une autre différence par rapport aux tests d’hypothèse nulle classique est que la distribution qui est utilisée est une distribution Cauchy plutôt qu’une distribution normale. Cependant, comme le montre la Figure 12, la différence entre les deux distribution est suffisamment subtile pour ne pas devoir s’en soucier. En effet, il n’est pas moins ou plus raisonnable de faire l’hypothèse d’une distribution normale et d’une distribution Cauchy pour a distribution des données.</p>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-232-1.png" width="672"></div>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="les-statistiques-descriptives.html"><span class="header-section-number">8</span> Les statistiques descriptives</a></div>
<div class="next"><a href="quel-outil-choisir.html"><span class="header-section-number">10</span> Quel outil choisir</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#les-diff%C3%A9rentes-m%C3%A9thodes-dinf%C3%A9rences-statistiques"><span class="header-section-number">9</span> Les différentes méthodes d’inférences statistiques</a></li>
<li><a class="nav-link" href="#introduction-2"><span class="header-section-number">9.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#lapproche-de-neyman-pearson"><span class="header-section-number">9.2</span> L’approche de Neyman-Pearson</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#une-approche-intuitive"><span class="header-section-number">9.2.1</span> Une approche intuitive</a></li>
<li><a class="nav-link" href="#quid-quand-cest-moins-%C3%A9vident"><span class="header-section-number">9.2.2</span> Quid quand c’est moins évident?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#lien-entre-la-taille-deffet-et-la-significativit%C3%A9"><span class="header-section-number">9.3</span> Lien entre la taille d’effet et la significativité</a></li>
<li><a class="nav-link" href="#quand-cest-encore-moins-%C3%A9vident"><span class="header-section-number">9.4</span> Quand c’est encore moins évident?</a></li>
<li>
<a class="nav-link" href="#en-synth%C3%A8se"><span class="header-section-number">9.5</span> En synthèse</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#une-approche-plus-formelle"><span class="header-section-number">9.5.1</span> Une approche plus formelle</a></li>
<li><a class="nav-link" href="#dautres-mani%C3%A8res-de-penser-les-statistiques"><span class="header-section-number">9.5.2</span> D’autres manières de penser les statistiques</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#lapproche-par-maximum-de-vraisemblance."><span class="header-section-number">9.6</span> L’approche par maximum de vraisemblance.</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#explication-math%C3%A9matique"><span class="header-section-number">9.6.1</span> Explication mathématique</a></li>
<li><a class="nav-link" href="#le-ratio-de-vraisemblance-lrt"><span class="header-section-number">9.6.2</span> Le ratio de vraisemblance (LRT)</a></li>
<li><a class="nav-link" href="#les-crit%C3%A8res-dinformation."><span class="header-section-number">9.6.3</span> Les critères d’information.</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#lapproche-bayesienne"><span class="header-section-number">9.7</span> L’approche bayesienne</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#les-facteurs-bayesiens-un-rapport-entre-deux-vraisemblances"><span class="header-section-number">9.7.1</span> Les facteurs bayesiens : un rapport entre deux vraisemblances</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Outils statistiques destinés aux psychologues</strong>" was written by Nicolas Stefaniak. It was last built on 2026-01-27.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
